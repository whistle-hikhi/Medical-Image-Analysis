{
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Import Libraries + Hyperparams"
      ],
      "metadata": {
        "id": "11-1bHuumCMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install segmentation_models_pytorch\n",
        "!pip install kornia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0hJQxk2ra_2",
        "outputId": "ca1a200a-9768-4e8f-fce7-b0ceac599667"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: segmentation_models_pytorch in /usr/local/lib/python3.10/dist-packages (0.3.3)\n\nRequirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (0.16.0+cu121)\n\nRequirement already satisfied: pretrainedmodels==0.7.4 in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (0.7.4)\n\nRequirement already satisfied: efficientnet-pytorch==0.7.1 in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (0.7.1)\n\nRequirement already satisfied: timm==0.9.2 in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (0.9.2)\n\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (4.66.1)\n\nRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (9.4.0)\n\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.1.0+cu121)\n\nRequirement already satisfied: munch in /usr/local/lib/python3.10/dist-packages (from pretrainedmodels==0.7.4->segmentation_models_pytorch) (4.0.0)\n\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation_models_pytorch) (6.0.1)\n\nRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation_models_pytorch) (0.20.2)\n\nRequirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation_models_pytorch) (0.4.1)\n\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (1.23.5)\n\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (2.31.0)\n\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.13.1)\n\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (4.5.0)\n\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.12)\n\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.2.1)\n\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.1.2)\n\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2023.6.0)\n\nRequirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.1.0)\n\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (23.2)\n\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (3.3.2)\n\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (3.6)\n\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (2.0.7)\n\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (2023.11.17)\n\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.1.3)\n\nRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.3.0)\n\nRequirement already satisfied: kornia in /usr/local/lib/python3.10/dist-packages (0.7.1)\n\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from kornia) (23.2)\n\nRequirement already satisfied: torch>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from kornia) (2.1.0+cu121)\n\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (3.13.1)\n\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (4.5.0)\n\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (1.12)\n\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (3.2.1)\n\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (3.1.2)\n\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (2023.6.0)\n\nRequirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (2.1.0)\n\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.1->kornia) (2.1.3)\n\nRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9.1->kornia) (1.3.0)\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfcvAV2ZCvcs",
        "outputId": "443837b2-d96d-46f4-ae56-4e08a16ba89e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.2.1)\n\nRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n\nRequirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.2)\n\nRequirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu121)\n\nRequirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.10.0)\n\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.13.1)\n\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.12)\n\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.2.1)\n\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2023.6.0)\n\nRequirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.1.0)\n\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n\nRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import cv2\n",
        "import logging\n",
        "import sys\n",
        "import time\n",
        "import torchvision.transforms as T\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import segmentation_models_pytorch as smp\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "from kornia.losses import focal_loss\n",
        "from torchmetrics import Accuracy, Precision, Recall, FBetaScore, Dice, JaccardIndex"
      ],
      "metadata": {
        "id": "mwKc26wsmpc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZmXnfJELDGPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_WORKERS = 0\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#Solver\n",
        "CLASSES = {0: \"Benign\", 1: \"Malignant\", 2: \"Normal\"}\n",
        "INPUT_SIZE = (448,448)\n",
        "BATCH_SIZE = # Điền batch size vào đây\n",
        "BASE_LR = # Điền learning rate phù hợp vào đây\n",
        "MAX_EPOCHS = # Số epoch train\n",
        "SAVE_INTERVAL = 10\n",
        "PATIENCE = 300\n",
        "N_SPLITS = # điền số K folds vào đây\n",
        "\n",
        "#Model\n",
        "ARCH = # chọn giữa ['unet', 'unetpp', , 'fpn', 'deeplabv3plus']\n",
        "ENCODER_NAME = # chọn giữa các kiến trúc ['resnet50', 'resnext50_32x4d', 'tu-wide_resnet50_2', 'efficientnet-b4']\n",
        "IN_CHANNELS = 3\n",
        "SEG_NUM_CLASSES = 2\n",
        "CLA_NUM_CLASSES = 3\n",
        "OUTPUT_ACTIVATION = None #None for logits\n",
        "\n",
        "#Loss coefficient weight\n",
        "ALPHA = # chọn số alpha hợp lý\n",
        "\n",
        "#Path\n",
        "OUTPUT_DIR = # điền vào đây\n",
        "DATASET_DIR = # điền vào đây\n",
        "CHECKPOINT = None\n",
        "\n",
        "#Eval\n",
        "WEIGHT = r\"\""
      ],
      "metadata": {
        "id": "xlorxtHLsbVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Utils"
      ],
      "metadata": {
        "id": "QMLdqRrvmuRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AverageMeter(object):\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "class UnNormalize(object):\n",
        "    def __init__(self, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
        "        Returns:\n",
        "            Tensor: Normalized image.\n",
        "        \"\"\"\n",
        "        for t, m, s in zip(tensor, self.mean, self.std):\n",
        "            t.mul_(s).add_(m)\n",
        "            # The normalize code -> t.sub_(m).div_(s)\n",
        "        return tensor"
      ],
      "metadata": {
        "id": "nmYkAUrYvi1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_overlap_metrics(pred, gt,eps=1e-5):\n",
        "    output = pred.view(-1,)\n",
        "    target = gt.view(-1,).float()\n",
        "\n",
        "    tp = torch.sum(output * target)  # TP\n",
        "    fp = torch.sum(output * (1 - target))  # FP\n",
        "    fn = torch.sum((1 - output) * target)  # FN\n",
        "    tn = torch.sum((1 - output) * (1 - target))  # TN\n",
        "\n",
        "    # pixel_acc = (tp + tn + eps) / (tp + tn + fp + fn + eps)\n",
        "    dice = (2 * tp + eps) / (2 * tp + fp + fn + eps)\n",
        "    iou = ( tp + eps) / ( tp + fp + fn + eps)\n",
        "    precision = (tp + eps) / (tp + fp + eps)\n",
        "    recall = (tp + eps) / (tp + fn + eps)\n",
        "#     specificity = (tn + eps) / (tn + fp + eps)\n",
        "\n",
        "    return iou, dice, precision, recall"
      ],
      "metadata": {
        "id": "6QTQH0Q_vawg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def setup_logger(logger_name, output_dir):\n",
        "    import os\n",
        "    logger = logging.getLogger(logger_name)\n",
        "    logger.setLevel(logging.DEBUG)\n",
        "    # create file handler which logs even debug messages\n",
        "    fh = logging.FileHandler(os.path.join(output_dir, 'log.log'))\n",
        "    fh.setLevel(logging.DEBUG)\n",
        "    # create console handler with a higher log level\n",
        "    ch = logging.StreamHandler()\n",
        "    ch.setLevel(logging.DEBUG)\n",
        "    # create formatter and add it to the handlers\n",
        "    formatter = logging.Formatter('%(asctime)s %(name)s %(levelname)s: %(message)s')\n",
        "    fh.setFormatter(formatter)\n",
        "    ch.setFormatter(formatter)\n",
        "    # add the handlers to logger\n",
        "    logger.addHandler(fh)\n",
        "    logger.addHandler(ch)\n",
        "    return logger\n",
        "\n",
        "\n",
        "def logging_hyperparameters(logger):\n",
        "    logger.info(\"==========Hyperparameters==========\")\n",
        "    logger.info(f\"Device: {DEVICE}\")\n",
        "    logger.info(f\"Architecture: {ARCH}\")\n",
        "    logger.info(f\"Encoder: {ENCODER_NAME}\")\n",
        "    logger.info(f\"Encoder weight: imagenet\")\n",
        "    logger.info(f\"Input size: {INPUT_SIZE}\")\n",
        "    logger.info(f\"Batch size: {BATCH_SIZE}\")\n",
        "    logger.info(f\"Base learning rate: {BASE_LR}\")\n",
        "    logger.info(f\"Max epochs: {MAX_EPOCHS}\")\n",
        "    logger.info(f\"Weight decay: {1e-5}\")\n",
        "    logger.info(\"===================================\")\n",
        "\n",
        "\n",
        "def init_path(task):\n",
        "    #Task == classification\n",
        "    if task == \"classification\":\n",
        "        weight_dir = os.path.join(OUTPUT_DIR, task, ENCODER_NAME)\n",
        "        os.makedirs(weight_dir, exist_ok=True)\n",
        "        log_dir = weight_dir\n",
        "        logger_name = f\"{task}_{ENCODER_NAME}\"\n",
        "    elif task == \"segmentation\":\n",
        "        weight_dir = os.path.join(OUTPUT_DIR, task, f\"{ENCODER_NAME}_{ARCH}\")\n",
        "        os.makedirs(weight_dir, exist_ok=True)\n",
        "        log_dir = weight_dir\n",
        "        logger_name = f\"{task}_{ENCODER_NAME}_{ARCH}\"\n",
        "    elif task == \"multitask\":\n",
        "        weight_dir = os.path.join(OUTPUT_DIR, f\"{ENCODER_NAME}_{ARCH}\")\n",
        "        os.makedirs(weight_dir, exist_ok=True)\n",
        "        log_dir = weight_dir\n",
        "        logger_name = f\"{task}_{ENCODER_NAME}_{ARCH}\"\n",
        "    return weight_dir, log_dir, logger_name"
      ],
      "metadata": {
        "id": "KopjSjPSvnUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Setup Data"
      ],
      "metadata": {
        "id": "i7eDsnQFmxRO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1. Download Dataset"
      ],
      "metadata": {
        "id": "bARB4le9rIP9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2. Setup dataloader"
      ],
      "metadata": {
        "id": "tzUaztG7u3Mv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def split_dataset(dataset_dir):\n",
        "    benign, malignant, normal = [], [], []\n",
        "    benign_images = # lấy tất cả những ảnh thuộc class benign (trong folder benign)\n",
        "    malignant_images = # lấy tất cả những ảnh thuộc class malignant (trong folder malignant)\n",
        "    normal_images = # lấy tất cả những ảnh thuộc class normal (trong folder normal)\n",
        "\n",
        "    for mask in benign_images:\n",
        "        if \"_mask\" in mask:\n",
        "            image = mask.replace('_mask.png', '.png')\n",
        "            benign.append((0, image, mask))\n",
        "    for mask in malignant_images:\n",
        "        if \"_mask\" in mask:\n",
        "            image = mask.replace('_mask.png', '.png')\n",
        "            malignant.append((1, image, mask))\n",
        "    for mask in normal_images:\n",
        "        if \"_mask\" in mask:\n",
        "            image = mask.replace('_mask.png', '.png')\n",
        "            normal.append((2, image, mask))\n",
        "\n",
        "    all_data = benign + malignant + normal\n",
        "    labels = [item[0] for item in all_data]\n",
        "\n",
        "    kf = StratifiedKFold(n_splits=N_SP)\n",
        "\n",
        "    folds = []\n",
        "\n",
        "    # Splitting data into folds\n",
        "    for train_index, val_index in kf.split(np.zeros(len(labels)), labels):\n",
        "        train_set = [all_data[i] for i in train_index]\n",
        "        val_set = [all_data[i] for i in val_index]\n",
        "        folds.append((train_set, val_set))\n",
        "\n",
        "    return folds"
      ],
      "metadata": {
        "id": "jxZotd14493O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fLNFx2GZ_o9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BUSI(Dataset):\n",
        "    def __init__(self, dataset_dir, train_set, val_set, input_size=(512,512), transform=None, target_transform=None, is_train=True):\n",
        "        self.input_size = input_size\n",
        "        self.dataset_dir = dataset_dir\n",
        "        self.is_train = is_train\n",
        "        if not os.path.exists(self.dataset_dir):\n",
        "            raise ValueError('BUSI dataset not found at {}'.format(self.dataset_dir))\n",
        "\n",
        "        for _, _, files in os.walk(self.dataset_dir):\n",
        "            for file in files:\n",
        "                if \"_mask_1\" in file:\n",
        "                    raise Exception(\"This class requires BUSI dataset with combined mask. It can be done by running the BUSI() function in the process_data.py at utils folder\")\n",
        "\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.train_set = train_set\n",
        "        self.val_set = val_set\n",
        "        if self.is_train:\n",
        "            self.images = train_set\n",
        "        else:\n",
        "            self.images = val_set\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        if self.is_train:\n",
        "            return len(self.train_set)\n",
        "        else:\n",
        "            return len(self.val_set)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label, image_path, mask_path = self.images[idx]\n",
        "        image = # đọc ảnh từ đường dẫn\n",
        "        mask = # đọc ảnh mask từ đường dẫn\n",
        "\n",
        "\n",
        "        image = # Resize tấm ảnh về kích thước mong muốn\n",
        "        mask = # Resize mask về kích thước mong muốn\n",
        "\n",
        "\n",
        "        #Normalize\n",
        "        mask = # normalize tấm ảnh về khoảng [0, 1]\n",
        "        mask = torch.from_numpy(mask).long()\n",
        "        mask = torch.nn.functional.one_hot(mask, num_classes=2).permute(2,0,1).long()\n",
        "\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform is not None:\n",
        "            mask = self.target_transform(mask)\n",
        "\n",
        "        return image, mask, label\n",
        "\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform is not None:\n",
        "            mask = self.target_transform(mask)\n",
        "\n",
        "        return image, mask, label\n",
        "\n",
        "    @property\n",
        "    def info(self):\n",
        "        print(f\"Dataset: BUSI\")\n",
        "        print(f\"Train: {len(self.train_set)} images\")\n",
        "        print(\"-\"*20)\n",
        "        print(f\"Benign: {len([image for image in self.train_set if image[0] == 0])} images\")\n",
        "        print(f\"Malignant: {len([image for image in self.train_set if image[0] == 1])} images\")\n",
        "        print(f\"Normal: {len([image for image in self.train_set if image[0] == 2])} images\")\n",
        "        print(\"-\"*20)\n",
        "        print(f\"Val: {len(self.val_set)} images\")\n",
        "        print(\"-\"*20)\n",
        "        print(f\"Benign: {len([image for image in self.val_set if image[0] == 0])} images\")\n",
        "        print(f\"Malignant: {len([image for image in self.val_set if image[0] == 1])} images\")\n",
        "        print(f\"Normal: {len([image for image in self.val_set if image[0] == 2])} images\")\n",
        "        print(\"-\"*20)\n",
        "\n"
      ],
      "metadata": {
        "id": "DUjnm8dkq3dK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k5PMNdjAAH5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Single Model"
      ],
      "metadata": {
        "id": "Xa895_NhtjQ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Setup model"
      ],
      "metadata": {
        "id": "zJbfv6JRuB-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PRETRAINED_WEIGHT_URL = {\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnext50_32x4d': 'https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth',\n",
        "    'tu-wide_resnet50_2': 'https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth',\n",
        "    'efficientnet-b4': 'https://download.pytorch.org/models/efficientnet_b4_rwightman-7eb33cd5.pth',\n",
        "}\n",
        "\n",
        "def segmentation_model(aux_param=None):\n",
        "    assert ARCH in ['unet', 'unetpp', 'deeplabv3plus', 'fpn'], \"Invalid architecture, must be ['unet', 'unetpp', 'deeplabv3plus', 'fpn']\"\n",
        "    assert ENCODER_NAME in ['resnet50', 'resnext50_32x4d', 'tu-wide_resnet50_2', 'efficientnet-b4'], \"Invalid encoder name, must be ['resnet50', 'resnext50_32x4d', 'tu-wide_resnet50_2', 'efficientnet-b4']\"\n",
        "    #Params\n",
        "\n",
        "    params = dict(\n",
        "        encoder_name = ENCODER_NAME,\n",
        "        encoder_depth = 5,\n",
        "        encoder_weights = \"imagenet\",\n",
        "        in_channels = IN_CHANNELS,\n",
        "        classes = SEG_NUM_CLASSES,\n",
        "        activation = OUTPUT_ACTIVATION,\n",
        "        aux_params = aux_param\n",
        "    )\n",
        "    MODELS = {\n",
        "        'unet':smp.Unet(**params),\n",
        "        'unetpp': smp.UnetPlusPlus(**params),\n",
        "        'deeplabv3plus': smp.DeepLabV3Plus(**params),\n",
        "        'fpn': smp.FPN(**params),\n",
        "\n",
        "    }\n",
        "    return MODELS[ARCH]\n",
        "\n",
        "def classification_model():\n",
        "    MODELS = {\n",
        "        'resnet50': torchvision.models.resnet50(weights='DEFAULT'),\n",
        "        'resnext50_32x4d':  #load kiến trúc resnext50,\n",
        "        'tu-wide_resnet50_2': # load kiến trúc tu-wide_resnet50_2,\n",
        "        'efficientnet-b4': # load kiến trúc efficientnet-b4\n",
        "    }\n",
        "    model = MODELS[ENCODER_NAME]\n",
        "\n",
        "    # Replace the last layer\n",
        "    if ENCODER_NAME == \"efficientnet-b4\":\n",
        "        state_dict = torch.hub.load_state_dict_from_url(PRETRAINED_WEIGHT_URL[ENCODER_NAME])\n",
        "        model.load_state_dict(state_dict)\n",
        "        model.classifier = # dùng classifier phù hợp\n",
        "    else:\n",
        "        model.fc = # dùng classifier phfu hợp\n",
        "\n",
        "    return model\n",
        "\n",
        "class TwoSingleModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.seg_model = # load segmentation_model\n",
        "        self.cla_model = # load classification_model\n",
        "\n",
        "    def forward(self, x):\n",
        "        seg_out = self.seg_model(x)\n",
        "        cla_out = self.cla_model(x)\n",
        "        return seg_out, cla_out\n"
      ],
      "metadata": {
        "id": "WwbsL3ygt2yW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2. Training Classification"
      ],
      "metadata": {
        "id": "842kDmqEwIkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(folds):\n",
        "\n",
        "    for fold in range(N_FOLDS):\n",
        "\n",
        "            #TASK\n",
        "        TASK = \"classification\"\n",
        "\n",
        "        #Path\n",
        "        weight_dir, log_dir, logger_name = init_path(TASK)\n",
        "\n",
        "        #Model\n",
        "        model = # load model\n",
        "\n",
        "        #Loss & Optimizer\n",
        "        model = model.to(DEVICE)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=BASE_LR, weight_decay=1e-5)\n",
        "\n",
        "\n",
        "        #Meters\n",
        "        train_loss_meter = AverageMeter()\n",
        "        val_loss_meter = AverageMeter()\n",
        "        acc_meter = AverageMeter()\n",
        "        precision_meter = AverageMeter()\n",
        "        recall_meter = AverageMeter()\n",
        "        f1_score_meter = AverageMeter()\n",
        "\n",
        "        train_images, val_images = folds[fold]\n",
        "\n",
        "        train_set = # khởi tạo dataset train\n",
        "        val_set = # khởi tạo dataset val\n",
        "\n",
        "        train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
        "        val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
        "\n",
        "        logger = setup_logger(logger_name, log_dir)\n",
        "        best_f1 = 0\n",
        "        stale = 0\n",
        "        start_epoch = 1\n",
        "\n",
        "        if CHECKPOINT is not None:\n",
        "            if os.path.exists(CHECKPOINT):\n",
        "                checkpoint = torch.load(CHECKPOINT)\n",
        "                model.load_state_dict(checkpoint['model_state_dict'])\n",
        "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "                start_epoch = checkpoint['epoch']\n",
        "                best_f1 = checkpoint['best_f1']\n",
        "                logger.info(f\"Resume training from epoch {start_epoch}\")\n",
        "            else:\n",
        "                logger.info(f\"Checkpoint not found, start training from epoch 1\")\n",
        "\n",
        "        #Logging hyperparameters\n",
        "        logging_hyperparameters(logger)\n",
        "\n",
        "\n",
        "        for epoch in range(start_epoch, 1+MAX_EPOCHS):\n",
        "            #Start time\n",
        "            start_time = time.time()\n",
        "            #Train\n",
        "            model.train()\n",
        "            #Reset meters\n",
        "            train_loss_meter.reset()\n",
        "            precision_meter.reset()\n",
        "            recall_meter.reset()\n",
        "            f1_score_meter.reset()\n",
        "            acc_meter.reset()\n",
        "\n",
        "            logger.info(\"Start training\")\n",
        "            for batch_idx, (image, _, label) in enumerate(train_loader):\n",
        "                n = image.shape[0]\n",
        "                optimizer.zero_grad()\n",
        "                image = image.to(DEVICE)\n",
        "                label = label.to(DEVICE)\n",
        "\n",
        "                output = # đưa ảnh qua model để tạo output\n",
        "                #Cal loss\n",
        "                train_loss = # dùng focal loss với biến alpha=0.25, gamma=2, reduction='mean'\n",
        "\n",
        "                # backward lại loss\n",
        "                # CODE HERE\n",
        "                optimizer.step()\n",
        "\n",
        "                train_loss_meter.update(train_loss.item(),n)\n",
        "\n",
        "                if batch_idx % 10 == 0:\n",
        "                    logger.info(f\"Epoch[{epoch}] - Fold[{fold}] - Iteration[{batch_idx}/{len(train_loader)}] Loss: {train_loss:.3f}\")\n",
        "            end_time = time.time()\n",
        "            logger.info(f\"Training Result: Epoch {epoch}/{MAX_EPOCHS} Fold {fold}/{N_FOLDS}, Loss: {train_loss_meter.avg:.3f}, Time epoch: {end_time-start_time:.3f}s\")\n",
        "\n",
        "            #Valid\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                for batch_idx, (image, _, label) in enumerate(val_loader):\n",
        "                    n = image.shape[0]\n",
        "                    image = image.to(DEVICE)\n",
        "                    label = label.to(DEVICE)\n",
        "\n",
        "                    output = model(image)\n",
        "                    val_loss = focal_loss(output, label, alpha=0.25, gamma=2,reduction='mean')\n",
        "\n",
        "                    #Calculate metrics\n",
        "                    #P, R and F1\n",
        "                    label = label.detach().cpu().numpy()\n",
        "                    output = output.argmax(1).detach().cpu().numpy()\n",
        "\n",
        "                    p_score = precision_score(label, output, average='macro', zero_division=0)\n",
        "                    r_score = recall_score(label, output, average='macro', zero_division=0)\n",
        "                    _f1_score = f1_score(label, output, average='macro')\n",
        "                    acc = accuracy_score(label, output)\n",
        "\n",
        "                    #Update meters\n",
        "                    val_loss_meter.update(val_loss.item(), n)\n",
        "                    acc_meter.update(acc.item(),n)\n",
        "                    precision_meter.update(p_score.item(), n)\n",
        "                    recall_meter.update(r_score.item(), n)\n",
        "                    f1_score_meter.update(_f1_score.item(), n)\n",
        "\n",
        "            logger.info(f\"Validation Result: Loss: {val_loss_meter.avg:.3f}, Accuracy: {acc_meter.avg:.3f} F1-Score: {f1_score_meter.avg:.3f}, Precision: {precision_meter.avg:.3f}, Recall: {recall_meter.avg:.3f}\")\n",
        "\n",
        "            #Save best model\n",
        "            to_save = {\n",
        "                    'epoch': epoch,\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'best_f1': best_f1,\n",
        "                }\n",
        "            if f1_score_meter.avg > best_f1: # best base on IoU score\n",
        "                logger.info(f\"Best model found at epoch {epoch}, saving model\")\n",
        "                torch.save(to_save, os.path.join(weight_dir,f\"best_epoch{epoch}_fold{fold}_{INPUT_SIZE[0]}_BS={BATCH_SIZE}_f1={f1_score_meter.avg:.3f}.pth\")) # only save best to prevent output memory exceed error\n",
        "                best_f1 = f1_score_meter.avg\n",
        "                stale = 0\n",
        "            else:\n",
        "                stale += 1\n",
        "                if stale > 300:\n",
        "                    logger.info(f\"No improvement {300} consecutive epochs, early stopping\")\n",
        "                    break\n",
        "            if epoch % SAVE_INTERVAL == 0 or epoch == MAX_EPOCHS:\n",
        "                logger.info(f\"Save model at epoch {epoch}, saving model\")\n",
        "                torch.save(to_save, os.path.join(weight_dir,f\"epoch_{epoch}_{fold}.pth\"))"
      ],
      "metadata": {
        "id": "0FAGnxCDwd1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOVH1a0CwrDq",
        "outputId": "23ccb1da-55df-4ad6-d2c1-e58d24de4ea8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2024-01-01 07:04:20,299 classification_efficientnet-b4 INFO: ==========Hyperparameters==========\n\nINFO:classification_efficientnet-b4:==========Hyperparameters==========\n\n2024-01-01 07:04:20,303 classification_efficientnet-b4 INFO: Device: cuda\n\nINFO:classification_efficientnet-b4:Device: cuda\n\n2024-01-01 07:04:20,305 classification_efficientnet-b4 INFO: Architecture: deeplabv3plus\n\nINFO:classification_efficientnet-b4:Architecture: deeplabv3plus\n\n2024-01-01 07:04:20,307 classification_efficientnet-b4 INFO: Encoder: efficientnet-b4\n\nINFO:classification_efficientnet-b4:Encoder: efficientnet-b4\n\n2024-01-01 07:04:20,309 classification_efficientnet-b4 INFO: Encoder weight: imagenet\n\nINFO:classification_efficientnet-b4:Encoder weight: imagenet\n\n2024-01-01 07:04:20,311 classification_efficientnet-b4 INFO: Input size: (448, 448)\n\nINFO:classification_efficientnet-b4:Input size: (448, 448)\n\n2024-01-01 07:04:20,312 classification_efficientnet-b4 INFO: Batch size: 8\n\nINFO:classification_efficientnet-b4:Batch size: 8\n\n2024-01-01 07:04:20,314 classification_efficientnet-b4 INFO: Base learning rate: 0.001\n\nINFO:classification_efficientnet-b4:Base learning rate: 0.001\n\n2024-01-01 07:04:20,316 classification_efficientnet-b4 INFO: Max epochs: 50\n\nINFO:classification_efficientnet-b4:Max epochs: 50\n\n2024-01-01 07:04:20,318 classification_efficientnet-b4 INFO: Weight decay: 1e-05\n\nINFO:classification_efficientnet-b4:Weight decay: 1e-05\n\n2024-01-01 07:04:20,320 classification_efficientnet-b4 INFO: ===================================\n\nINFO:classification_efficientnet-b4:===================================\n\n2024-01-01 07:04:20,325 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:04:22,531 classification_efficientnet-b4 INFO: Epoch[1] Iteration[0/78] Loss: 0.091\n\nINFO:classification_efficientnet-b4:Epoch[1] Iteration[0/78] Loss: 0.091\n\n2024-01-01 07:04:27,943 classification_efficientnet-b4 INFO: Epoch[1] Iteration[10/78] Loss: 0.054\n\nINFO:classification_efficientnet-b4:Epoch[1] Iteration[10/78] Loss: 0.054\n\n2024-01-01 07:04:33,010 classification_efficientnet-b4 INFO: Epoch[1] Iteration[20/78] Loss: 0.034\n\nINFO:classification_efficientnet-b4:Epoch[1] Iteration[20/78] Loss: 0.034\n\n2024-01-01 07:04:38,350 classification_efficientnet-b4 INFO: Epoch[1] Iteration[30/78] Loss: 0.032\n\nINFO:classification_efficientnet-b4:Epoch[1] Iteration[30/78] Loss: 0.032\n\n2024-01-01 07:04:43,623 classification_efficientnet-b4 INFO: Epoch[1] Iteration[40/78] Loss: 0.033\n\nINFO:classification_efficientnet-b4:Epoch[1] Iteration[40/78] Loss: 0.033\n\n2024-01-01 07:04:48,798 classification_efficientnet-b4 INFO: Epoch[1] Iteration[50/78] Loss: 0.038\n\nINFO:classification_efficientnet-b4:Epoch[1] Iteration[50/78] Loss: 0.038\n\n2024-01-01 07:04:54,208 classification_efficientnet-b4 INFO: Epoch[1] Iteration[60/78] Loss: 0.008\n\nINFO:classification_efficientnet-b4:Epoch[1] Iteration[60/78] Loss: 0.008\n\n2024-01-01 07:04:59,336 classification_efficientnet-b4 INFO: Epoch[1] Iteration[70/78] Loss: 0.022\n\nINFO:classification_efficientnet-b4:Epoch[1] Iteration[70/78] Loss: 0.022\n\n2024-01-01 07:05:03,048 classification_efficientnet-b4 INFO: Training Result: Epoch 1/50, Loss: 0.039, Time epoch: 42.726s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 1/50, Loss: 0.039, Time epoch: 42.726s\n\n2024-01-01 07:05:07,916 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.038, Accuracy: 0.726 F1-Score: 0.587, Precision: 0.678, Recall: 0.551\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.038, Accuracy: 0.726 F1-Score: 0.587, Precision: 0.678, Recall: 0.551\n\n2024-01-01 07:05:07,926 classification_efficientnet-b4 INFO: Best model found at epoch 1, saving model\n\nINFO:classification_efficientnet-b4:Best model found at epoch 1, saving model\n\n2024-01-01 07:05:08,455 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:05:08,997 classification_efficientnet-b4 INFO: Epoch[2] Iteration[0/78] Loss: 0.028\n\nINFO:classification_efficientnet-b4:Epoch[2] Iteration[0/78] Loss: 0.028\n\n2024-01-01 07:05:14,313 classification_efficientnet-b4 INFO: Epoch[2] Iteration[10/78] Loss: 0.017\n\nINFO:classification_efficientnet-b4:Epoch[2] Iteration[10/78] Loss: 0.017\n\n2024-01-01 07:05:20,872 classification_efficientnet-b4 INFO: Epoch[2] Iteration[20/78] Loss: 0.018\n\nINFO:classification_efficientnet-b4:Epoch[2] Iteration[20/78] Loss: 0.018\n\n2024-01-01 07:05:26,150 classification_efficientnet-b4 INFO: Epoch[2] Iteration[30/78] Loss: 0.009\n\nINFO:classification_efficientnet-b4:Epoch[2] Iteration[30/78] Loss: 0.009\n\n2024-01-01 07:05:31,791 classification_efficientnet-b4 INFO: Epoch[2] Iteration[40/78] Loss: 0.011\n\nINFO:classification_efficientnet-b4:Epoch[2] Iteration[40/78] Loss: 0.011\n\n2024-01-01 07:05:37,158 classification_efficientnet-b4 INFO: Epoch[2] Iteration[50/78] Loss: 0.007\n\nINFO:classification_efficientnet-b4:Epoch[2] Iteration[50/78] Loss: 0.007\n\n2024-01-01 07:05:43,775 classification_efficientnet-b4 INFO: Epoch[2] Iteration[60/78] Loss: 0.013\n\nINFO:classification_efficientnet-b4:Epoch[2] Iteration[60/78] Loss: 0.013\n\n2024-01-01 07:05:50,479 classification_efficientnet-b4 INFO: Epoch[2] Iteration[70/78] Loss: 0.047\n\nINFO:classification_efficientnet-b4:Epoch[2] Iteration[70/78] Loss: 0.047\n\n2024-01-01 07:05:54,434 classification_efficientnet-b4 INFO: Training Result: Epoch 2/50, Loss: 0.022, Time epoch: 45.981s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 2/50, Loss: 0.022, Time epoch: 45.981s\n\n2024-01-01 07:05:59,671 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.030, Accuracy: 0.745 F1-Score: 0.545, Precision: 0.631, Recall: 0.501\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.030, Accuracy: 0.745 F1-Score: 0.545, Precision: 0.631, Recall: 0.501\n\n2024-01-01 07:05:59,687 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:06:00,226 classification_efficientnet-b4 INFO: Epoch[3] Iteration[0/78] Loss: 0.010\n\nINFO:classification_efficientnet-b4:Epoch[3] Iteration[0/78] Loss: 0.010\n\n2024-01-01 07:06:05,551 classification_efficientnet-b4 INFO: Epoch[3] Iteration[10/78] Loss: 0.005\n\nINFO:classification_efficientnet-b4:Epoch[3] Iteration[10/78] Loss: 0.005\n\n2024-01-01 07:06:11,170 classification_efficientnet-b4 INFO: Epoch[3] Iteration[20/78] Loss: 0.027\n\nINFO:classification_efficientnet-b4:Epoch[3] Iteration[20/78] Loss: 0.027\n\n2024-01-01 07:06:16,519 classification_efficientnet-b4 INFO: Epoch[3] Iteration[30/78] Loss: 0.005\n\nINFO:classification_efficientnet-b4:Epoch[3] Iteration[30/78] Loss: 0.005\n\n2024-01-01 07:06:22,005 classification_efficientnet-b4 INFO: Epoch[3] Iteration[40/78] Loss: 0.015\n\nINFO:classification_efficientnet-b4:Epoch[3] Iteration[40/78] Loss: 0.015\n\n2024-01-01 07:06:27,594 classification_efficientnet-b4 INFO: Epoch[3] Iteration[50/78] Loss: 0.019\n\nINFO:classification_efficientnet-b4:Epoch[3] Iteration[50/78] Loss: 0.019\n\n2024-01-01 07:06:32,933 classification_efficientnet-b4 INFO: Epoch[3] Iteration[60/78] Loss: 0.006\n\nINFO:classification_efficientnet-b4:Epoch[3] Iteration[60/78] Loss: 0.006\n\n2024-01-01 07:06:38,544 classification_efficientnet-b4 INFO: Epoch[3] Iteration[70/78] Loss: 0.008\n\nINFO:classification_efficientnet-b4:Epoch[3] Iteration[70/78] Loss: 0.008\n\n2024-01-01 07:06:42,221 classification_efficientnet-b4 INFO: Training Result: Epoch 3/50, Loss: 0.010, Time epoch: 42.536s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 3/50, Loss: 0.010, Time epoch: 42.536s\n\n2024-01-01 07:06:47,626 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.036, Accuracy: 0.752 F1-Score: 0.590, Precision: 0.678, Recall: 0.555\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.036, Accuracy: 0.752 F1-Score: 0.590, Precision: 0.678, Recall: 0.555\n\n2024-01-01 07:06:47,642 classification_efficientnet-b4 INFO: Best model found at epoch 3, saving model\n\nINFO:classification_efficientnet-b4:Best model found at epoch 3, saving model\n\n2024-01-01 07:06:48,535 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:06:49,147 classification_efficientnet-b4 INFO: Epoch[4] Iteration[0/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[4] Iteration[0/78] Loss: 0.001\n\n2024-01-01 07:06:54,873 classification_efficientnet-b4 INFO: Epoch[4] Iteration[10/78] Loss: 0.019\n\nINFO:classification_efficientnet-b4:Epoch[4] Iteration[10/78] Loss: 0.019\n\n2024-01-01 07:07:00,538 classification_efficientnet-b4 INFO: Epoch[4] Iteration[20/78] Loss: 0.005\n\nINFO:classification_efficientnet-b4:Epoch[4] Iteration[20/78] Loss: 0.005\n\n2024-01-01 07:07:06,110 classification_efficientnet-b4 INFO: Epoch[4] Iteration[30/78] Loss: 0.006\n\nINFO:classification_efficientnet-b4:Epoch[4] Iteration[30/78] Loss: 0.006\n\n2024-01-01 07:07:11,370 classification_efficientnet-b4 INFO: Epoch[4] Iteration[40/78] Loss: 0.006\n\nINFO:classification_efficientnet-b4:Epoch[4] Iteration[40/78] Loss: 0.006\n\n2024-01-01 07:07:16,932 classification_efficientnet-b4 INFO: Epoch[4] Iteration[50/78] Loss: 0.010\n\nINFO:classification_efficientnet-b4:Epoch[4] Iteration[50/78] Loss: 0.010\n\n2024-01-01 07:07:22,284 classification_efficientnet-b4 INFO: Epoch[4] Iteration[60/78] Loss: 0.022\n\nINFO:classification_efficientnet-b4:Epoch[4] Iteration[60/78] Loss: 0.022\n\n2024-01-01 07:07:27,774 classification_efficientnet-b4 INFO: Epoch[4] Iteration[70/78] Loss: 0.021\n\nINFO:classification_efficientnet-b4:Epoch[4] Iteration[70/78] Loss: 0.021\n\n2024-01-01 07:07:31,557 classification_efficientnet-b4 INFO: Training Result: Epoch 4/50, Loss: 0.011, Time epoch: 43.025s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 4/50, Loss: 0.011, Time epoch: 43.025s\n\n2024-01-01 07:07:36,093 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.034, Accuracy: 0.758 F1-Score: 0.565, Precision: 0.648, Recall: 0.529\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.034, Accuracy: 0.758 F1-Score: 0.565, Precision: 0.648, Recall: 0.529\n\n2024-01-01 07:07:36,107 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:07:36,633 classification_efficientnet-b4 INFO: Epoch[5] Iteration[0/78] Loss: 0.004\n\nINFO:classification_efficientnet-b4:Epoch[5] Iteration[0/78] Loss: 0.004\n\n2024-01-01 07:07:42,328 classification_efficientnet-b4 INFO: Epoch[5] Iteration[10/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[5] Iteration[10/78] Loss: 0.001\n\n2024-01-01 07:07:47,688 classification_efficientnet-b4 INFO: Epoch[5] Iteration[20/78] Loss: 0.018\n\nINFO:classification_efficientnet-b4:Epoch[5] Iteration[20/78] Loss: 0.018\n\n2024-01-01 07:07:53,218 classification_efficientnet-b4 INFO: Epoch[5] Iteration[30/78] Loss: 0.003\n\nINFO:classification_efficientnet-b4:Epoch[5] Iteration[30/78] Loss: 0.003\n\n2024-01-01 07:07:58,701 classification_efficientnet-b4 INFO: Epoch[5] Iteration[40/78] Loss: 0.016\n\nINFO:classification_efficientnet-b4:Epoch[5] Iteration[40/78] Loss: 0.016\n\n2024-01-01 07:08:04,037 classification_efficientnet-b4 INFO: Epoch[5] Iteration[50/78] Loss: 0.027\n\nINFO:classification_efficientnet-b4:Epoch[5] Iteration[50/78] Loss: 0.027\n\n2024-01-01 07:08:09,579 classification_efficientnet-b4 INFO: Epoch[5] Iteration[60/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[5] Iteration[60/78] Loss: 0.001\n\n2024-01-01 07:08:14,934 classification_efficientnet-b4 INFO: Epoch[5] Iteration[70/78] Loss: 0.005\n\nINFO:classification_efficientnet-b4:Epoch[5] Iteration[70/78] Loss: 0.005\n\n2024-01-01 07:08:18,645 classification_efficientnet-b4 INFO: Training Result: Epoch 5/50, Loss: 0.008, Time epoch: 42.540s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 5/50, Loss: 0.008, Time epoch: 42.540s\n\n2024-01-01 07:08:23,597 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.033, Accuracy: 0.815 F1-Score: 0.610, Precision: 0.665, Recall: 0.577\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.033, Accuracy: 0.815 F1-Score: 0.610, Precision: 0.665, Recall: 0.577\n\n2024-01-01 07:08:23,608 classification_efficientnet-b4 INFO: Best model found at epoch 5, saving model\n\nINFO:classification_efficientnet-b4:Best model found at epoch 5, saving model\n\n2024-01-01 07:08:24,162 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:08:24,702 classification_efficientnet-b4 INFO: Epoch[6] Iteration[0/78] Loss: 0.012\n\nINFO:classification_efficientnet-b4:Epoch[6] Iteration[0/78] Loss: 0.012\n\n2024-01-01 07:08:30,027 classification_efficientnet-b4 INFO: Epoch[6] Iteration[10/78] Loss: 0.008\n\nINFO:classification_efficientnet-b4:Epoch[6] Iteration[10/78] Loss: 0.008\n\n2024-01-01 07:08:35,672 classification_efficientnet-b4 INFO: Epoch[6] Iteration[20/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[6] Iteration[20/78] Loss: 0.001\n\n2024-01-01 07:08:41,026 classification_efficientnet-b4 INFO: Epoch[6] Iteration[30/78] Loss: 0.002\n\nINFO:classification_efficientnet-b4:Epoch[6] Iteration[30/78] Loss: 0.002\n\n2024-01-01 07:08:46,624 classification_efficientnet-b4 INFO: Epoch[6] Iteration[40/78] Loss: 0.007\n\nINFO:classification_efficientnet-b4:Epoch[6] Iteration[40/78] Loss: 0.007\n\n2024-01-01 07:08:52,060 classification_efficientnet-b4 INFO: Epoch[6] Iteration[50/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[6] Iteration[50/78] Loss: 0.001\n\n2024-01-01 07:08:57,480 classification_efficientnet-b4 INFO: Epoch[6] Iteration[60/78] Loss: 0.008\n\nINFO:classification_efficientnet-b4:Epoch[6] Iteration[60/78] Loss: 0.008\n\n2024-01-01 07:09:03,021 classification_efficientnet-b4 INFO: Epoch[6] Iteration[70/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[6] Iteration[70/78] Loss: 0.001\n\n2024-01-01 07:09:06,717 classification_efficientnet-b4 INFO: Training Result: Epoch 6/50, Loss: 0.009, Time epoch: 42.557s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 6/50, Loss: 0.009, Time epoch: 42.557s\n\n2024-01-01 07:09:11,554 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.034, Accuracy: 0.803 F1-Score: 0.564, Precision: 0.614, Recall: 0.533\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.034, Accuracy: 0.803 F1-Score: 0.564, Precision: 0.614, Recall: 0.533\n\n2024-01-01 07:09:11,580 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:09:12,182 classification_efficientnet-b4 INFO: Epoch[7] Iteration[0/78] Loss: 0.005\n\nINFO:classification_efficientnet-b4:Epoch[7] Iteration[0/78] Loss: 0.005\n\n2024-01-01 07:09:17,615 classification_efficientnet-b4 INFO: Epoch[7] Iteration[10/78] Loss: 0.011\n\nINFO:classification_efficientnet-b4:Epoch[7] Iteration[10/78] Loss: 0.011\n\n2024-01-01 07:09:22,938 classification_efficientnet-b4 INFO: Epoch[7] Iteration[20/78] Loss: 0.015\n\nINFO:classification_efficientnet-b4:Epoch[7] Iteration[20/78] Loss: 0.015\n\n2024-01-01 07:09:28,514 classification_efficientnet-b4 INFO: Epoch[7] Iteration[30/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[7] Iteration[30/78] Loss: 0.001\n\n2024-01-01 07:09:33,893 classification_efficientnet-b4 INFO: Epoch[7] Iteration[40/78] Loss: 0.003\n\nINFO:classification_efficientnet-b4:Epoch[7] Iteration[40/78] Loss: 0.003\n\n2024-01-01 07:09:39,498 classification_efficientnet-b4 INFO: Epoch[7] Iteration[50/78] Loss: 0.008\n\nINFO:classification_efficientnet-b4:Epoch[7] Iteration[50/78] Loss: 0.008\n\n2024-01-01 07:09:44,856 classification_efficientnet-b4 INFO: Epoch[7] Iteration[60/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[7] Iteration[60/78] Loss: 0.001\n\n2024-01-01 07:09:50,253 classification_efficientnet-b4 INFO: Epoch[7] Iteration[70/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[7] Iteration[70/78] Loss: 0.000\n\n2024-01-01 07:09:54,127 classification_efficientnet-b4 INFO: Training Result: Epoch 7/50, Loss: 0.008, Time epoch: 42.551s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 7/50, Loss: 0.008, Time epoch: 42.551s\n\n2024-01-01 07:09:59,038 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.034, Accuracy: 0.860 F1-Score: 0.639, Precision: 0.678, Recall: 0.611\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.034, Accuracy: 0.860 F1-Score: 0.639, Precision: 0.678, Recall: 0.611\n\n2024-01-01 07:09:59,056 classification_efficientnet-b4 INFO: Best model found at epoch 7, saving model\n\nINFO:classification_efficientnet-b4:Best model found at epoch 7, saving model\n\n2024-01-01 07:09:59,856 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:10:00,461 classification_efficientnet-b4 INFO: Epoch[8] Iteration[0/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[8] Iteration[0/78] Loss: 0.000\n\n2024-01-01 07:10:06,178 classification_efficientnet-b4 INFO: Epoch[8] Iteration[10/78] Loss: 0.002\n\nINFO:classification_efficientnet-b4:Epoch[8] Iteration[10/78] Loss: 0.002\n\n2024-01-01 07:10:11,501 classification_efficientnet-b4 INFO: Epoch[8] Iteration[20/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[8] Iteration[20/78] Loss: 0.000\n\n2024-01-01 07:10:17,051 classification_efficientnet-b4 INFO: Epoch[8] Iteration[30/78] Loss: 0.004\n\nINFO:classification_efficientnet-b4:Epoch[8] Iteration[30/78] Loss: 0.004\n\n2024-01-01 07:10:22,458 classification_efficientnet-b4 INFO: Epoch[8] Iteration[40/78] Loss: 0.006\n\nINFO:classification_efficientnet-b4:Epoch[8] Iteration[40/78] Loss: 0.006\n\n2024-01-01 07:10:27,812 classification_efficientnet-b4 INFO: Epoch[8] Iteration[50/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[8] Iteration[50/78] Loss: 0.000\n\n2024-01-01 07:10:33,413 classification_efficientnet-b4 INFO: Epoch[8] Iteration[60/78] Loss: 0.002\n\nINFO:classification_efficientnet-b4:Epoch[8] Iteration[60/78] Loss: 0.002\n\n2024-01-01 07:10:38,747 classification_efficientnet-b4 INFO: Epoch[8] Iteration[70/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[8] Iteration[70/78] Loss: 0.001\n\n2024-01-01 07:10:42,601 classification_efficientnet-b4 INFO: Training Result: Epoch 8/50, Loss: 0.004, Time epoch: 42.749s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 8/50, Loss: 0.004, Time epoch: 42.749s\n\n2024-01-01 07:10:47,269 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.035, Accuracy: 0.809 F1-Score: 0.588, Precision: 0.643, Recall: 0.553\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.035, Accuracy: 0.809 F1-Score: 0.588, Precision: 0.643, Recall: 0.553\n\n2024-01-01 07:10:47,284 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:10:47,820 classification_efficientnet-b4 INFO: Epoch[9] Iteration[0/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[9] Iteration[0/78] Loss: 0.000\n\n2024-01-01 07:10:53,120 classification_efficientnet-b4 INFO: Epoch[9] Iteration[10/78] Loss: 0.016\n\nINFO:classification_efficientnet-b4:Epoch[9] Iteration[10/78] Loss: 0.016\n\n2024-01-01 07:10:58,679 classification_efficientnet-b4 INFO: Epoch[9] Iteration[20/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[9] Iteration[20/78] Loss: 0.001\n\n2024-01-01 07:11:04,022 classification_efficientnet-b4 INFO: Epoch[9] Iteration[30/78] Loss: 0.063\n\nINFO:classification_efficientnet-b4:Epoch[9] Iteration[30/78] Loss: 0.063\n\n2024-01-01 07:11:09,618 classification_efficientnet-b4 INFO: Epoch[9] Iteration[40/78] Loss: 0.020\n\nINFO:classification_efficientnet-b4:Epoch[9] Iteration[40/78] Loss: 0.020\n\n2024-01-01 07:11:14,948 classification_efficientnet-b4 INFO: Epoch[9] Iteration[50/78] Loss: 0.002\n\nINFO:classification_efficientnet-b4:Epoch[9] Iteration[50/78] Loss: 0.002\n\n2024-01-01 07:11:20,369 classification_efficientnet-b4 INFO: Epoch[9] Iteration[60/78] Loss: 0.009\n\nINFO:classification_efficientnet-b4:Epoch[9] Iteration[60/78] Loss: 0.009\n\n2024-01-01 07:11:25,954 classification_efficientnet-b4 INFO: Epoch[9] Iteration[70/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[9] Iteration[70/78] Loss: 0.001\n\n2024-01-01 07:11:29,641 classification_efficientnet-b4 INFO: Training Result: Epoch 9/50, Loss: 0.010, Time epoch: 42.359s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 9/50, Loss: 0.010, Time epoch: 42.359s\n\n2024-01-01 07:11:34,565 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.036, Accuracy: 0.752 F1-Score: 0.524, Precision: 0.602, Recall: 0.478\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.036, Accuracy: 0.752 F1-Score: 0.524, Precision: 0.602, Recall: 0.478\n\n2024-01-01 07:11:34,588 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:11:35,195 classification_efficientnet-b4 INFO: Epoch[10] Iteration[0/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[10] Iteration[0/78] Loss: 0.001\n\n2024-01-01 07:11:40,607 classification_efficientnet-b4 INFO: Epoch[10] Iteration[10/78] Loss: 0.062\n\nINFO:classification_efficientnet-b4:Epoch[10] Iteration[10/78] Loss: 0.062\n\n2024-01-01 07:11:46,012 classification_efficientnet-b4 INFO: Epoch[10] Iteration[20/78] Loss: 0.002\n\nINFO:classification_efficientnet-b4:Epoch[10] Iteration[20/78] Loss: 0.002\n\n2024-01-01 07:11:51,570 classification_efficientnet-b4 INFO: Epoch[10] Iteration[30/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[10] Iteration[30/78] Loss: 0.000\n\n2024-01-01 07:11:56,927 classification_efficientnet-b4 INFO: Epoch[10] Iteration[40/78] Loss: 0.005\n\nINFO:classification_efficientnet-b4:Epoch[10] Iteration[40/78] Loss: 0.005\n\n2024-01-01 07:12:02,549 classification_efficientnet-b4 INFO: Epoch[10] Iteration[50/78] Loss: 0.002\n\nINFO:classification_efficientnet-b4:Epoch[10] Iteration[50/78] Loss: 0.002\n\n2024-01-01 07:12:07,872 classification_efficientnet-b4 INFO: Epoch[10] Iteration[60/78] Loss: 0.011\n\nINFO:classification_efficientnet-b4:Epoch[10] Iteration[60/78] Loss: 0.011\n\n2024-01-01 07:12:13,393 classification_efficientnet-b4 INFO: Epoch[10] Iteration[70/78] Loss: 0.009\n\nINFO:classification_efficientnet-b4:Epoch[10] Iteration[70/78] Loss: 0.009\n\n2024-01-01 07:12:17,127 classification_efficientnet-b4 INFO: Training Result: Epoch 10/50, Loss: 0.007, Time epoch: 42.543s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 10/50, Loss: 0.007, Time epoch: 42.543s\n\n2024-01-01 07:12:21,649 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.038, Accuracy: 0.707 F1-Score: 0.624, Precision: 0.712, Recall: 0.587\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.038, Accuracy: 0.707 F1-Score: 0.624, Precision: 0.712, Recall: 0.587\n\n2024-01-01 07:12:21,663 classification_efficientnet-b4 INFO: Save model at epoch 10, saving model\n\nINFO:classification_efficientnet-b4:Save model at epoch 10, saving model\n\n2024-01-01 07:12:22,200 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:12:22,741 classification_efficientnet-b4 INFO: Epoch[11] Iteration[0/78] Loss: 0.008\n\nINFO:classification_efficientnet-b4:Epoch[11] Iteration[0/78] Loss: 0.008\n\n2024-01-01 07:12:28,361 classification_efficientnet-b4 INFO: Epoch[11] Iteration[10/78] Loss: 0.022\n\nINFO:classification_efficientnet-b4:Epoch[11] Iteration[10/78] Loss: 0.022\n\n2024-01-01 07:12:33,685 classification_efficientnet-b4 INFO: Epoch[11] Iteration[20/78] Loss: 0.023\n\nINFO:classification_efficientnet-b4:Epoch[11] Iteration[20/78] Loss: 0.023\n\n2024-01-01 07:12:39,165 classification_efficientnet-b4 INFO: Epoch[11] Iteration[30/78] Loss: 0.014\n\nINFO:classification_efficientnet-b4:Epoch[11] Iteration[30/78] Loss: 0.014\n\n2024-01-01 07:12:44,575 classification_efficientnet-b4 INFO: Epoch[11] Iteration[40/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[11] Iteration[40/78] Loss: 0.001\n\n2024-01-01 07:12:49,934 classification_efficientnet-b4 INFO: Epoch[11] Iteration[50/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[11] Iteration[50/78] Loss: 0.000\n\n2024-01-01 07:12:55,492 classification_efficientnet-b4 INFO: Epoch[11] Iteration[60/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[11] Iteration[60/78] Loss: 0.000\n\n2024-01-01 07:13:00,846 classification_efficientnet-b4 INFO: Epoch[11] Iteration[70/78] Loss: 0.002\n\nINFO:classification_efficientnet-b4:Epoch[11] Iteration[70/78] Loss: 0.002\n\n2024-01-01 07:13:04,571 classification_efficientnet-b4 INFO: Training Result: Epoch 11/50, Loss: 0.006, Time epoch: 42.374s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 11/50, Loss: 0.006, Time epoch: 42.374s\n\n2024-01-01 07:13:09,369 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.040, Accuracy: 0.828 F1-Score: 0.556, Precision: 0.601, Recall: 0.525\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.040, Accuracy: 0.828 F1-Score: 0.556, Precision: 0.601, Recall: 0.525\n\n2024-01-01 07:13:09,383 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:13:09,917 classification_efficientnet-b4 INFO: Epoch[12] Iteration[0/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[12] Iteration[0/78] Loss: 0.001\n\n2024-01-01 07:13:15,257 classification_efficientnet-b4 INFO: Epoch[12] Iteration[10/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[12] Iteration[10/78] Loss: 0.001\n\n2024-01-01 07:13:20,782 classification_efficientnet-b4 INFO: Epoch[12] Iteration[20/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[12] Iteration[20/78] Loss: 0.000\n\n2024-01-01 07:13:26,105 classification_efficientnet-b4 INFO: Epoch[12] Iteration[30/78] Loss: 0.003\n\nINFO:classification_efficientnet-b4:Epoch[12] Iteration[30/78] Loss: 0.003\n\n2024-01-01 07:13:31,636 classification_efficientnet-b4 INFO: Epoch[12] Iteration[40/78] Loss: 0.005\n\nINFO:classification_efficientnet-b4:Epoch[12] Iteration[40/78] Loss: 0.005\n\n2024-01-01 07:13:37,050 classification_efficientnet-b4 INFO: Epoch[12] Iteration[50/78] Loss: 0.079\n\nINFO:classification_efficientnet-b4:Epoch[12] Iteration[50/78] Loss: 0.079\n\n2024-01-01 07:13:42,449 classification_efficientnet-b4 INFO: Epoch[12] Iteration[60/78] Loss: 0.004\n\nINFO:classification_efficientnet-b4:Epoch[12] Iteration[60/78] Loss: 0.004\n\n2024-01-01 07:13:48,018 classification_efficientnet-b4 INFO: Epoch[12] Iteration[70/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[12] Iteration[70/78] Loss: 0.001\n\n2024-01-01 07:13:51,710 classification_efficientnet-b4 INFO: Training Result: Epoch 12/50, Loss: 0.005, Time epoch: 42.328s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 12/50, Loss: 0.005, Time epoch: 42.328s\n\n2024-01-01 07:13:56,498 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.039, Accuracy: 0.809 F1-Score: 0.510, Precision: 0.558, Recall: 0.476\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.039, Accuracy: 0.809 F1-Score: 0.510, Precision: 0.558, Recall: 0.476\n\n2024-01-01 07:13:56,522 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:13:57,092 classification_efficientnet-b4 INFO: Epoch[13] Iteration[0/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[13] Iteration[0/78] Loss: 0.000\n\n2024-01-01 07:14:02,503 classification_efficientnet-b4 INFO: Epoch[13] Iteration[10/78] Loss: 0.008\n\nINFO:classification_efficientnet-b4:Epoch[13] Iteration[10/78] Loss: 0.008\n\n2024-01-01 07:14:07,863 classification_efficientnet-b4 INFO: Epoch[13] Iteration[20/78] Loss: 0.002\n\nINFO:classification_efficientnet-b4:Epoch[13] Iteration[20/78] Loss: 0.002\n\n2024-01-01 07:14:13,445 classification_efficientnet-b4 INFO: Epoch[13] Iteration[30/78] Loss: 0.045\n\nINFO:classification_efficientnet-b4:Epoch[13] Iteration[30/78] Loss: 0.045\n\n2024-01-01 07:14:18,820 classification_efficientnet-b4 INFO: Epoch[13] Iteration[40/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[13] Iteration[40/78] Loss: 0.001\n\n2024-01-01 07:14:24,457 classification_efficientnet-b4 INFO: Epoch[13] Iteration[50/78] Loss: 0.004\n\nINFO:classification_efficientnet-b4:Epoch[13] Iteration[50/78] Loss: 0.004\n\n2024-01-01 07:14:29,748 classification_efficientnet-b4 INFO: Epoch[13] Iteration[60/78] Loss: 0.004\n\nINFO:classification_efficientnet-b4:Epoch[13] Iteration[60/78] Loss: 0.004\n\n2024-01-01 07:14:35,212 classification_efficientnet-b4 INFO: Epoch[13] Iteration[70/78] Loss: 0.003\n\nINFO:classification_efficientnet-b4:Epoch[13] Iteration[70/78] Loss: 0.003\n\n2024-01-01 07:14:38,981 classification_efficientnet-b4 INFO: Training Result: Epoch 13/50, Loss: 0.006, Time epoch: 42.463s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 13/50, Loss: 0.006, Time epoch: 42.463s\n\n2024-01-01 07:14:43,443 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.040, Accuracy: 0.771 F1-Score: 0.605, Precision: 0.678, Recall: 0.564\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.040, Accuracy: 0.771 F1-Score: 0.605, Precision: 0.678, Recall: 0.564\n\n2024-01-01 07:14:43,457 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:14:43,980 classification_efficientnet-b4 INFO: Epoch[14] Iteration[0/78] Loss: 0.006\n\nINFO:classification_efficientnet-b4:Epoch[14] Iteration[0/78] Loss: 0.006\n\n2024-01-01 07:14:49,557 classification_efficientnet-b4 INFO: Epoch[14] Iteration[10/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[14] Iteration[10/78] Loss: 0.001\n\n2024-01-01 07:14:54,904 classification_efficientnet-b4 INFO: Epoch[14] Iteration[20/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[14] Iteration[20/78] Loss: 0.000\n\n2024-01-01 07:15:00,299 classification_efficientnet-b4 INFO: Epoch[14] Iteration[30/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[14] Iteration[30/78] Loss: 0.000\n\n2024-01-01 07:15:05,824 classification_efficientnet-b4 INFO: Epoch[14] Iteration[40/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[14] Iteration[40/78] Loss: 0.000\n\n2024-01-01 07:15:11,156 classification_efficientnet-b4 INFO: Epoch[14] Iteration[50/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[14] Iteration[50/78] Loss: 0.000\n\n2024-01-01 07:15:16,673 classification_efficientnet-b4 INFO: Epoch[14] Iteration[60/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[14] Iteration[60/78] Loss: 0.000\n\n2024-01-01 07:15:22,034 classification_efficientnet-b4 INFO: Epoch[14] Iteration[70/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[14] Iteration[70/78] Loss: 0.000\n\n2024-01-01 07:15:25,708 classification_efficientnet-b4 INFO: Training Result: Epoch 14/50, Loss: 0.003, Time epoch: 42.253s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 14/50, Loss: 0.003, Time epoch: 42.253s\n\n2024-01-01 07:15:30,680 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.039, Accuracy: 0.841 F1-Score: 0.605, Precision: 0.653, Recall: 0.571\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.039, Accuracy: 0.841 F1-Score: 0.605, Precision: 0.653, Recall: 0.571\n\n2024-01-01 07:15:30,698 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:15:31,234 classification_efficientnet-b4 INFO: Epoch[15] Iteration[0/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[15] Iteration[0/78] Loss: 0.000\n\n2024-01-01 07:15:36,564 classification_efficientnet-b4 INFO: Epoch[15] Iteration[10/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[15] Iteration[10/78] Loss: 0.000\n\n2024-01-01 07:15:42,197 classification_efficientnet-b4 INFO: Epoch[15] Iteration[20/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[15] Iteration[20/78] Loss: 0.000\n\n2024-01-01 07:15:47,493 classification_efficientnet-b4 INFO: Epoch[15] Iteration[30/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[15] Iteration[30/78] Loss: 0.000\n\n2024-01-01 07:15:52,938 classification_efficientnet-b4 INFO: Epoch[15] Iteration[40/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[15] Iteration[40/78] Loss: 0.000\n\n2024-01-01 07:15:58,417 classification_efficientnet-b4 INFO: Epoch[15] Iteration[50/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[15] Iteration[50/78] Loss: 0.000\n\n2024-01-01 07:16:03,777 classification_efficientnet-b4 INFO: Epoch[15] Iteration[60/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[15] Iteration[60/78] Loss: 0.000\n\n2024-01-01 07:16:09,396 classification_efficientnet-b4 INFO: Epoch[15] Iteration[70/78] Loss: 0.046\n\nINFO:classification_efficientnet-b4:Epoch[15] Iteration[70/78] Loss: 0.046\n\n2024-01-01 07:16:13,023 classification_efficientnet-b4 INFO: Training Result: Epoch 15/50, Loss: 0.003, Time epoch: 42.328s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 15/50, Loss: 0.003, Time epoch: 42.328s\n\n2024-01-01 07:16:17,547 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.038, Accuracy: 0.796 F1-Score: 0.564, Precision: 0.618, Recall: 0.528\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.038, Accuracy: 0.796 F1-Score: 0.564, Precision: 0.618, Recall: 0.528\n\n2024-01-01 07:16:17,567 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:16:18,162 classification_efficientnet-b4 INFO: Epoch[16] Iteration[0/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[16] Iteration[0/78] Loss: 0.000\n\n2024-01-01 07:16:23,654 classification_efficientnet-b4 INFO: Epoch[16] Iteration[10/78] Loss: 0.003\n\nINFO:classification_efficientnet-b4:Epoch[16] Iteration[10/78] Loss: 0.003\n\n2024-01-01 07:16:28,983 classification_efficientnet-b4 INFO: Epoch[16] Iteration[20/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[16] Iteration[20/78] Loss: 0.001\n\n2024-01-01 07:16:34,945 classification_efficientnet-b4 INFO: Epoch[16] Iteration[30/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[16] Iteration[30/78] Loss: 0.000\n\n2024-01-01 07:16:40,819 classification_efficientnet-b4 INFO: Epoch[16] Iteration[40/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[16] Iteration[40/78] Loss: 0.000\n\n2024-01-01 07:16:46,408 classification_efficientnet-b4 INFO: Epoch[16] Iteration[50/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[16] Iteration[50/78] Loss: 0.001\n\n2024-01-01 07:16:51,717 classification_efficientnet-b4 INFO: Epoch[16] Iteration[60/78] Loss: 0.003\n\nINFO:classification_efficientnet-b4:Epoch[16] Iteration[60/78] Loss: 0.003\n\n2024-01-01 07:16:57,055 classification_efficientnet-b4 INFO: Epoch[16] Iteration[70/78] Loss: 0.002\n\nINFO:classification_efficientnet-b4:Epoch[16] Iteration[70/78] Loss: 0.002\n\n2024-01-01 07:17:00,934 classification_efficientnet-b4 INFO: Training Result: Epoch 16/50, Loss: 0.005, Time epoch: 43.372s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 16/50, Loss: 0.005, Time epoch: 43.372s\n\n2024-01-01 07:17:05,411 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.037, Accuracy: 0.777 F1-Score: 0.587, Precision: 0.661, Recall: 0.546\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.037, Accuracy: 0.777 F1-Score: 0.587, Precision: 0.661, Recall: 0.546\n\n2024-01-01 07:17:05,428 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:17:05,979 classification_efficientnet-b4 INFO: Epoch[17] Iteration[0/78] Loss: 0.021\n\nINFO:classification_efficientnet-b4:Epoch[17] Iteration[0/78] Loss: 0.021\n\n2024-01-01 07:17:11,435 classification_efficientnet-b4 INFO: Epoch[17] Iteration[10/78] Loss: 0.012\n\nINFO:classification_efficientnet-b4:Epoch[17] Iteration[10/78] Loss: 0.012\n\n2024-01-01 07:17:16,911 classification_efficientnet-b4 INFO: Epoch[17] Iteration[20/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[17] Iteration[20/78] Loss: 0.000\n\n2024-01-01 07:17:22,234 classification_efficientnet-b4 INFO: Epoch[17] Iteration[30/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[17] Iteration[30/78] Loss: 0.000\n\n2024-01-01 07:17:28,871 classification_efficientnet-b4 INFO: Epoch[17] Iteration[40/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[17] Iteration[40/78] Loss: 0.000\n\n2024-01-01 07:17:34,840 classification_efficientnet-b4 INFO: Epoch[17] Iteration[50/78] Loss: 0.005\n\nINFO:classification_efficientnet-b4:Epoch[17] Iteration[50/78] Loss: 0.005\n\n2024-01-01 07:17:40,717 classification_efficientnet-b4 INFO: Epoch[17] Iteration[60/78] Loss: 0.002\n\nINFO:classification_efficientnet-b4:Epoch[17] Iteration[60/78] Loss: 0.002\n\n2024-01-01 07:17:46,750 classification_efficientnet-b4 INFO: Epoch[17] Iteration[70/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[17] Iteration[70/78] Loss: 0.001\n\n2024-01-01 07:17:51,242 classification_efficientnet-b4 INFO: Training Result: Epoch 17/50, Loss: 0.006, Time epoch: 45.818s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 17/50, Loss: 0.006, Time epoch: 45.818s\n\n2024-01-01 07:17:55,775 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.038, Accuracy: 0.777 F1-Score: 0.525, Precision: 0.584, Recall: 0.489\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.038, Accuracy: 0.777 F1-Score: 0.525, Precision: 0.584, Recall: 0.489\n\n2024-01-01 07:17:55,788 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:17:56,329 classification_efficientnet-b4 INFO: Epoch[18] Iteration[0/78] Loss: 0.006\n\nINFO:classification_efficientnet-b4:Epoch[18] Iteration[0/78] Loss: 0.006\n\n2024-01-01 07:18:02,025 classification_efficientnet-b4 INFO: Epoch[18] Iteration[10/78] Loss: 0.012\n\nINFO:classification_efficientnet-b4:Epoch[18] Iteration[10/78] Loss: 0.012\n\n2024-01-01 07:18:07,559 classification_efficientnet-b4 INFO: Epoch[18] Iteration[20/78] Loss: 0.008\n\nINFO:classification_efficientnet-b4:Epoch[18] Iteration[20/78] Loss: 0.008\n\n2024-01-01 07:18:12,877 classification_efficientnet-b4 INFO: Epoch[18] Iteration[30/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[18] Iteration[30/78] Loss: 0.000\n\n2024-01-01 07:18:18,478 classification_efficientnet-b4 INFO: Epoch[18] Iteration[40/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[18] Iteration[40/78] Loss: 0.000\n\n2024-01-01 07:18:23,813 classification_efficientnet-b4 INFO: Epoch[18] Iteration[50/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[18] Iteration[50/78] Loss: 0.001\n\n2024-01-01 07:18:29,297 classification_efficientnet-b4 INFO: Epoch[18] Iteration[60/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[18] Iteration[60/78] Loss: 0.001\n\n2024-01-01 07:18:34,717 classification_efficientnet-b4 INFO: Epoch[18] Iteration[70/78] Loss: 0.027\n\nINFO:classification_efficientnet-b4:Epoch[18] Iteration[70/78] Loss: 0.027\n\n2024-01-01 07:18:38,394 classification_efficientnet-b4 INFO: Training Result: Epoch 18/50, Loss: 0.005, Time epoch: 42.608s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 18/50, Loss: 0.005, Time epoch: 42.608s\n\n2024-01-01 07:18:43,601 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.038, Accuracy: 0.790 F1-Score: 0.677, Precision: 0.746, Recall: 0.647\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.038, Accuracy: 0.790 F1-Score: 0.677, Precision: 0.746, Recall: 0.647\n\n2024-01-01 07:18:43,619 classification_efficientnet-b4 INFO: Best model found at epoch 18, saving model\n\nINFO:classification_efficientnet-b4:Best model found at epoch 18, saving model\n\n2024-01-01 07:18:44,526 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:18:45,142 classification_efficientnet-b4 INFO: Epoch[19] Iteration[0/78] Loss: 0.004\n\nINFO:classification_efficientnet-b4:Epoch[19] Iteration[0/78] Loss: 0.004\n\n2024-01-01 07:18:50,558 classification_efficientnet-b4 INFO: Epoch[19] Iteration[10/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[19] Iteration[10/78] Loss: 0.001\n\n2024-01-01 07:18:55,900 classification_efficientnet-b4 INFO: Epoch[19] Iteration[20/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[19] Iteration[20/78] Loss: 0.000\n\n2024-01-01 07:19:01,461 classification_efficientnet-b4 INFO: Epoch[19] Iteration[30/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[19] Iteration[30/78] Loss: 0.001\n\n2024-01-01 07:19:06,746 classification_efficientnet-b4 INFO: Epoch[19] Iteration[40/78] Loss: 0.003\n\nINFO:classification_efficientnet-b4:Epoch[19] Iteration[40/78] Loss: 0.003\n\n2024-01-01 07:19:12,350 classification_efficientnet-b4 INFO: Epoch[19] Iteration[50/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[19] Iteration[50/78] Loss: 0.001\n\n2024-01-01 07:19:17,685 classification_efficientnet-b4 INFO: Epoch[19] Iteration[60/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[19] Iteration[60/78] Loss: 0.000\n\n2024-01-01 07:19:23,067 classification_efficientnet-b4 INFO: Epoch[19] Iteration[70/78] Loss: 0.012\n\nINFO:classification_efficientnet-b4:Epoch[19] Iteration[70/78] Loss: 0.012\n\n2024-01-01 07:19:26,917 classification_efficientnet-b4 INFO: Training Result: Epoch 19/50, Loss: 0.007, Time epoch: 42.398s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 19/50, Loss: 0.007, Time epoch: 42.398s\n\n2024-01-01 07:19:31,395 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.039, Accuracy: 0.809 F1-Score: 0.585, Precision: 0.632, Recall: 0.561\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.039, Accuracy: 0.809 F1-Score: 0.585, Precision: 0.632, Recall: 0.561\n\n2024-01-01 07:19:31,410 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:19:31,943 classification_efficientnet-b4 INFO: Epoch[20] Iteration[0/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[20] Iteration[0/78] Loss: 0.000\n\n2024-01-01 07:19:37,756 classification_efficientnet-b4 INFO: Epoch[20] Iteration[10/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[20] Iteration[10/78] Loss: 0.000\n\n2024-01-01 07:19:43,116 classification_efficientnet-b4 INFO: Epoch[20] Iteration[20/78] Loss: 0.020\n\nINFO:classification_efficientnet-b4:Epoch[20] Iteration[20/78] Loss: 0.020\n\n2024-01-01 07:19:48,513 classification_efficientnet-b4 INFO: Epoch[20] Iteration[30/78] Loss: 0.008\n\nINFO:classification_efficientnet-b4:Epoch[20] Iteration[30/78] Loss: 0.008\n\n2024-01-01 07:19:54,100 classification_efficientnet-b4 INFO: Epoch[20] Iteration[40/78] Loss: 0.060\n\nINFO:classification_efficientnet-b4:Epoch[20] Iteration[40/78] Loss: 0.060\n\n2024-01-01 07:19:59,413 classification_efficientnet-b4 INFO: Epoch[20] Iteration[50/78] Loss: 0.002\n\nINFO:classification_efficientnet-b4:Epoch[20] Iteration[50/78] Loss: 0.002\n\n2024-01-01 07:20:04,995 classification_efficientnet-b4 INFO: Epoch[20] Iteration[60/78] Loss: 0.004\n\nINFO:classification_efficientnet-b4:Epoch[20] Iteration[60/78] Loss: 0.004\n\n2024-01-01 07:20:10,321 classification_efficientnet-b4 INFO: Epoch[20] Iteration[70/78] Loss: 0.002\n\nINFO:classification_efficientnet-b4:Epoch[20] Iteration[70/78] Loss: 0.002\n\n2024-01-01 07:20:13,996 classification_efficientnet-b4 INFO: Training Result: Epoch 20/50, Loss: 0.017, Time epoch: 42.588s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 20/50, Loss: 0.017, Time epoch: 42.588s\n\n2024-01-01 07:20:18,991 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.038, Accuracy: 0.803 F1-Score: 0.593, Precision: 0.661, Recall: 0.557\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.038, Accuracy: 0.803 F1-Score: 0.593, Precision: 0.661, Recall: 0.557\n\n2024-01-01 07:20:19,002 classification_efficientnet-b4 INFO: Save model at epoch 20, saving model\n\nINFO:classification_efficientnet-b4:Save model at epoch 20, saving model\n\n2024-01-01 07:20:19,578 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:20:20,126 classification_efficientnet-b4 INFO: Epoch[21] Iteration[0/78] Loss: 0.004\n\nINFO:classification_efficientnet-b4:Epoch[21] Iteration[0/78] Loss: 0.004\n\n2024-01-01 07:20:25,426 classification_efficientnet-b4 INFO: Epoch[21] Iteration[10/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[21] Iteration[10/78] Loss: 0.001\n\n2024-01-01 07:20:31,047 classification_efficientnet-b4 INFO: Epoch[21] Iteration[20/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[21] Iteration[20/78] Loss: 0.000\n\n2024-01-01 07:20:36,414 classification_efficientnet-b4 INFO: Epoch[21] Iteration[30/78] Loss: 0.002\n\nINFO:classification_efficientnet-b4:Epoch[21] Iteration[30/78] Loss: 0.002\n\n2024-01-01 07:20:41,948 classification_efficientnet-b4 INFO: Epoch[21] Iteration[40/78] Loss: 0.011\n\nINFO:classification_efficientnet-b4:Epoch[21] Iteration[40/78] Loss: 0.011\n\n2024-01-01 07:20:47,319 classification_efficientnet-b4 INFO: Epoch[21] Iteration[50/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[21] Iteration[50/78] Loss: 0.001\n\n2024-01-01 07:20:52,614 classification_efficientnet-b4 INFO: Epoch[21] Iteration[60/78] Loss: 0.015\n\nINFO:classification_efficientnet-b4:Epoch[21] Iteration[60/78] Loss: 0.015\n\n2024-01-01 07:20:58,231 classification_efficientnet-b4 INFO: Epoch[21] Iteration[70/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[21] Iteration[70/78] Loss: 0.000\n\n2024-01-01 07:21:01,877 classification_efficientnet-b4 INFO: Training Result: Epoch 21/50, Loss: 0.004, Time epoch: 42.303s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 21/50, Loss: 0.004, Time epoch: 42.303s\n\n2024-01-01 07:21:06,518 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.038, Accuracy: 0.783 F1-Score: 0.705, Precision: 0.789, Recall: 0.676\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.038, Accuracy: 0.783 F1-Score: 0.705, Precision: 0.789, Recall: 0.676\n\n2024-01-01 07:21:06,536 classification_efficientnet-b4 INFO: Best model found at epoch 21, saving model\n\nINFO:classification_efficientnet-b4:Best model found at epoch 21, saving model\n\n2024-01-01 07:21:07,363 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:21:07,982 classification_efficientnet-b4 INFO: Epoch[22] Iteration[0/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[22] Iteration[0/78] Loss: 0.001\n\n2024-01-01 07:21:13,388 classification_efficientnet-b4 INFO: Epoch[22] Iteration[10/78] Loss: 0.025\n\nINFO:classification_efficientnet-b4:Epoch[22] Iteration[10/78] Loss: 0.025\n\n2024-01-01 07:21:18,744 classification_efficientnet-b4 INFO: Epoch[22] Iteration[20/78] Loss: 0.005\n\nINFO:classification_efficientnet-b4:Epoch[22] Iteration[20/78] Loss: 0.005\n\n2024-01-01 07:21:25,410 classification_efficientnet-b4 INFO: Epoch[22] Iteration[30/78] Loss: 0.004\n\nINFO:classification_efficientnet-b4:Epoch[22] Iteration[30/78] Loss: 0.004\n\n2024-01-01 07:21:30,713 classification_efficientnet-b4 INFO: Epoch[22] Iteration[40/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[22] Iteration[40/78] Loss: 0.001\n\n2024-01-01 07:21:36,304 classification_efficientnet-b4 INFO: Epoch[22] Iteration[50/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[22] Iteration[50/78] Loss: 0.000\n\n2024-01-01 07:21:41,616 classification_efficientnet-b4 INFO: Epoch[22] Iteration[60/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[22] Iteration[60/78] Loss: 0.000\n\n2024-01-01 07:21:47,178 classification_efficientnet-b4 INFO: Epoch[22] Iteration[70/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[22] Iteration[70/78] Loss: 0.000\n\n2024-01-01 07:21:50,857 classification_efficientnet-b4 INFO: Training Result: Epoch 22/50, Loss: 0.004, Time epoch: 43.498s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 22/50, Loss: 0.004, Time epoch: 43.498s\n\n2024-01-01 07:21:55,326 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.038, Accuracy: 0.828 F1-Score: 0.568, Precision: 0.610, Recall: 0.538\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.038, Accuracy: 0.828 F1-Score: 0.568, Precision: 0.610, Recall: 0.538\n\n2024-01-01 07:21:55,341 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:21:55,870 classification_efficientnet-b4 INFO: Epoch[23] Iteration[0/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[23] Iteration[0/78] Loss: 0.000\n\n2024-01-01 07:22:01,418 classification_efficientnet-b4 INFO: Epoch[23] Iteration[10/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[23] Iteration[10/78] Loss: 0.000\n\n2024-01-01 07:22:06,730 classification_efficientnet-b4 INFO: Epoch[23] Iteration[20/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[23] Iteration[20/78] Loss: 0.000\n\n2024-01-01 07:22:12,202 classification_efficientnet-b4 INFO: Epoch[23] Iteration[30/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[23] Iteration[30/78] Loss: 0.000\n\n2024-01-01 07:22:17,574 classification_efficientnet-b4 INFO: Epoch[23] Iteration[40/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[23] Iteration[40/78] Loss: 0.000\n\n2024-01-01 07:22:22,869 classification_efficientnet-b4 INFO: Epoch[23] Iteration[50/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[23] Iteration[50/78] Loss: 0.000\n\n2024-01-01 07:22:28,424 classification_efficientnet-b4 INFO: Epoch[23] Iteration[60/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[23] Iteration[60/78] Loss: 0.000\n\n2024-01-01 07:22:33,781 classification_efficientnet-b4 INFO: Epoch[23] Iteration[70/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[23] Iteration[70/78] Loss: 0.001\n\n2024-01-01 07:22:37,582 classification_efficientnet-b4 INFO: Training Result: Epoch 23/50, Loss: 0.002, Time epoch: 42.243s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 23/50, Loss: 0.002, Time epoch: 42.243s\n\n2024-01-01 07:22:42,331 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.038, Accuracy: 0.815 F1-Score: 0.545, Precision: 0.593, Recall: 0.511\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.038, Accuracy: 0.815 F1-Score: 0.545, Precision: 0.593, Recall: 0.511\n\n2024-01-01 07:22:42,347 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:22:42,876 classification_efficientnet-b4 INFO: Epoch[24] Iteration[0/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[24] Iteration[0/78] Loss: 0.000\n\n2024-01-01 07:22:48,248 classification_efficientnet-b4 INFO: Epoch[24] Iteration[10/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[24] Iteration[10/78] Loss: 0.000\n\n2024-01-01 07:22:53,804 classification_efficientnet-b4 INFO: Epoch[24] Iteration[20/78] Loss: 0.002\n\nINFO:classification_efficientnet-b4:Epoch[24] Iteration[20/78] Loss: 0.002\n\n2024-01-01 07:22:59,159 classification_efficientnet-b4 INFO: Epoch[24] Iteration[30/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[24] Iteration[30/78] Loss: 0.001\n\n2024-01-01 07:23:04,743 classification_efficientnet-b4 INFO: Epoch[24] Iteration[40/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[24] Iteration[40/78] Loss: 0.000\n\n2024-01-01 07:23:10,083 classification_efficientnet-b4 INFO: Epoch[24] Iteration[50/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[24] Iteration[50/78] Loss: 0.000\n\n2024-01-01 07:23:15,395 classification_efficientnet-b4 INFO: Epoch[24] Iteration[60/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[24] Iteration[60/78] Loss: 0.001\n\n2024-01-01 07:23:20,951 classification_efficientnet-b4 INFO: Epoch[24] Iteration[70/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[24] Iteration[70/78] Loss: 0.001\n\n2024-01-01 07:23:24,625 classification_efficientnet-b4 INFO: Training Result: Epoch 24/50, Loss: 0.007, Time epoch: 42.282s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 24/50, Loss: 0.007, Time epoch: 42.282s\n\n2024-01-01 07:23:29,359 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.037, Accuracy: 0.790 F1-Score: 0.545, Precision: 0.602, Recall: 0.510\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.037, Accuracy: 0.790 F1-Score: 0.545, Precision: 0.602, Recall: 0.510\n\n2024-01-01 07:23:29,385 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:23:29,956 classification_efficientnet-b4 INFO: Epoch[25] Iteration[0/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[25] Iteration[0/78] Loss: 0.001\n\n2024-01-01 07:23:35,332 classification_efficientnet-b4 INFO: Epoch[25] Iteration[10/78] Loss: 0.011\n\nINFO:classification_efficientnet-b4:Epoch[25] Iteration[10/78] Loss: 0.011\n\n2024-01-01 07:23:40,703 classification_efficientnet-b4 INFO: Epoch[25] Iteration[20/78] Loss: 0.036\n\nINFO:classification_efficientnet-b4:Epoch[25] Iteration[20/78] Loss: 0.036\n\n2024-01-01 07:23:46,290 classification_efficientnet-b4 INFO: Epoch[25] Iteration[30/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[25] Iteration[30/78] Loss: 0.000\n\n2024-01-01 07:23:51,657 classification_efficientnet-b4 INFO: Epoch[25] Iteration[40/78] Loss: 0.002\n\nINFO:classification_efficientnet-b4:Epoch[25] Iteration[40/78] Loss: 0.002\n\n2024-01-01 07:23:57,313 classification_efficientnet-b4 INFO: Epoch[25] Iteration[50/78] Loss: 0.016\n\nINFO:classification_efficientnet-b4:Epoch[25] Iteration[50/78] Loss: 0.016\n\n2024-01-01 07:24:02,684 classification_efficientnet-b4 INFO: Epoch[25] Iteration[60/78] Loss: 0.011\n\nINFO:classification_efficientnet-b4:Epoch[25] Iteration[60/78] Loss: 0.011\n\n2024-01-01 07:24:08,157 classification_efficientnet-b4 INFO: Epoch[25] Iteration[70/78] Loss: 0.014\n\nINFO:classification_efficientnet-b4:Epoch[25] Iteration[70/78] Loss: 0.014\n\n2024-01-01 07:24:12,004 classification_efficientnet-b4 INFO: Training Result: Epoch 25/50, Loss: 0.005, Time epoch: 42.624s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 25/50, Loss: 0.005, Time epoch: 42.624s\n\n2024-01-01 07:24:16,507 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.037, Accuracy: 0.841 F1-Score: 0.642, Precision: 0.687, Recall: 0.614\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.037, Accuracy: 0.841 F1-Score: 0.642, Precision: 0.687, Recall: 0.614\n\n2024-01-01 07:24:16,523 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:24:17,064 classification_efficientnet-b4 INFO: Epoch[26] Iteration[0/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[26] Iteration[0/78] Loss: 0.000\n\n2024-01-01 07:24:22,657 classification_efficientnet-b4 INFO: Epoch[26] Iteration[10/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[26] Iteration[10/78] Loss: 0.000\n\n2024-01-01 07:24:28,092 classification_efficientnet-b4 INFO: Epoch[26] Iteration[20/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[26] Iteration[20/78] Loss: 0.000\n\n2024-01-01 07:24:33,449 classification_efficientnet-b4 INFO: Epoch[26] Iteration[30/78] Loss: 0.009\n\nINFO:classification_efficientnet-b4:Epoch[26] Iteration[30/78] Loss: 0.009\n\n2024-01-01 07:24:39,071 classification_efficientnet-b4 INFO: Epoch[26] Iteration[40/78] Loss: 0.004\n\nINFO:classification_efficientnet-b4:Epoch[26] Iteration[40/78] Loss: 0.004\n\n2024-01-01 07:24:44,464 classification_efficientnet-b4 INFO: Epoch[26] Iteration[50/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[26] Iteration[50/78] Loss: 0.001\n\n2024-01-01 07:24:50,154 classification_efficientnet-b4 INFO: Epoch[26] Iteration[60/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[26] Iteration[60/78] Loss: 0.000\n\n2024-01-01 07:24:55,578 classification_efficientnet-b4 INFO: Epoch[26] Iteration[70/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[26] Iteration[70/78] Loss: 0.000\n\n2024-01-01 07:24:59,393 classification_efficientnet-b4 INFO: Training Result: Epoch 26/50, Loss: 0.001, Time epoch: 42.874s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 26/50, Loss: 0.001, Time epoch: 42.874s\n\n2024-01-01 07:25:04,774 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.037, Accuracy: 0.803 F1-Score: 0.592, Precision: 0.653, Recall: 0.553\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.037, Accuracy: 0.803 F1-Score: 0.592, Precision: 0.653, Recall: 0.553\n\n2024-01-01 07:25:04,790 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:25:05,336 classification_efficientnet-b4 INFO: Epoch[27] Iteration[0/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[27] Iteration[0/78] Loss: 0.000\n\n2024-01-01 07:25:10,791 classification_efficientnet-b4 INFO: Epoch[27] Iteration[10/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[27] Iteration[10/78] Loss: 0.000\n\n2024-01-01 07:25:16,456 classification_efficientnet-b4 INFO: Epoch[27] Iteration[20/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[27] Iteration[20/78] Loss: 0.000\n\n2024-01-01 07:25:21,922 classification_efficientnet-b4 INFO: Epoch[27] Iteration[30/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[27] Iteration[30/78] Loss: 0.000\n\n2024-01-01 07:25:27,510 classification_efficientnet-b4 INFO: Epoch[27] Iteration[40/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[27] Iteration[40/78] Loss: 0.000\n\n2024-01-01 07:25:32,923 classification_efficientnet-b4 INFO: Epoch[27] Iteration[50/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[27] Iteration[50/78] Loss: 0.000\n\n2024-01-01 07:25:38,364 classification_efficientnet-b4 INFO: Epoch[27] Iteration[60/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[27] Iteration[60/78] Loss: 0.000\n\n2024-01-01 07:25:44,118 classification_efficientnet-b4 INFO: Epoch[27] Iteration[70/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[27] Iteration[70/78] Loss: 0.000\n\n2024-01-01 07:25:47,817 classification_efficientnet-b4 INFO: Training Result: Epoch 27/50, Loss: 0.001, Time epoch: 43.029s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 27/50, Loss: 0.001, Time epoch: 43.029s\n\n2024-01-01 07:25:52,785 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.037, Accuracy: 0.828 F1-Score: 0.616, Precision: 0.660, Recall: 0.588\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.037, Accuracy: 0.828 F1-Score: 0.616, Precision: 0.660, Recall: 0.588\n\n2024-01-01 07:25:52,806 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:25:53,434 classification_efficientnet-b4 INFO: Epoch[28] Iteration[0/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[28] Iteration[0/78] Loss: 0.000\n\n2024-01-01 07:25:59,019 classification_efficientnet-b4 INFO: Epoch[28] Iteration[10/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[28] Iteration[10/78] Loss: 0.000\n\n2024-01-01 07:26:04,396 classification_efficientnet-b4 INFO: Epoch[28] Iteration[20/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[28] Iteration[20/78] Loss: 0.000\n\n2024-01-01 07:26:10,086 classification_efficientnet-b4 INFO: Epoch[28] Iteration[30/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[28] Iteration[30/78] Loss: 0.000\n\n2024-01-01 07:26:15,456 classification_efficientnet-b4 INFO: Epoch[28] Iteration[40/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[28] Iteration[40/78] Loss: 0.000\n\n2024-01-01 07:26:21,117 classification_efficientnet-b4 INFO: Epoch[28] Iteration[50/78] Loss: 0.026\n\nINFO:classification_efficientnet-b4:Epoch[28] Iteration[50/78] Loss: 0.026\n\n2024-01-01 07:26:26,592 classification_efficientnet-b4 INFO: Epoch[28] Iteration[60/78] Loss: 0.008\n\nINFO:classification_efficientnet-b4:Epoch[28] Iteration[60/78] Loss: 0.008\n\n2024-01-01 07:26:32,133 classification_efficientnet-b4 INFO: Epoch[28] Iteration[70/78] Loss: 0.005\n\nINFO:classification_efficientnet-b4:Epoch[28] Iteration[70/78] Loss: 0.005\n\n2024-01-01 07:26:36,165 classification_efficientnet-b4 INFO: Training Result: Epoch 28/50, Loss: 0.007, Time epoch: 43.364s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 28/50, Loss: 0.007, Time epoch: 43.364s\n\n2024-01-01 07:26:40,926 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.037, Accuracy: 0.783 F1-Score: 0.476, Precision: 0.531, Recall: 0.437\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.037, Accuracy: 0.783 F1-Score: 0.476, Precision: 0.531, Recall: 0.437\n\n2024-01-01 07:26:40,941 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:26:41,482 classification_efficientnet-b4 INFO: Epoch[29] Iteration[0/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[29] Iteration[0/78] Loss: 0.001\n\n2024-01-01 07:26:47,202 classification_efficientnet-b4 INFO: Epoch[29] Iteration[10/78] Loss: 0.025\n\nINFO:classification_efficientnet-b4:Epoch[29] Iteration[10/78] Loss: 0.025\n\n2024-01-01 07:26:52,688 classification_efficientnet-b4 INFO: Epoch[29] Iteration[20/78] Loss: 0.010\n\nINFO:classification_efficientnet-b4:Epoch[29] Iteration[20/78] Loss: 0.010\n\n2024-01-01 07:26:58,142 classification_efficientnet-b4 INFO: Epoch[29] Iteration[30/78] Loss: 0.014\n\nINFO:classification_efficientnet-b4:Epoch[29] Iteration[30/78] Loss: 0.014\n\n2024-01-01 07:27:03,839 classification_efficientnet-b4 INFO: Epoch[29] Iteration[40/78] Loss: 0.003\n\nINFO:classification_efficientnet-b4:Epoch[29] Iteration[40/78] Loss: 0.003\n\n2024-01-01 07:27:09,261 classification_efficientnet-b4 INFO: Epoch[29] Iteration[50/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[29] Iteration[50/78] Loss: 0.000\n\n2024-01-01 07:27:14,974 classification_efficientnet-b4 INFO: Epoch[29] Iteration[60/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[29] Iteration[60/78] Loss: 0.000\n\n2024-01-01 07:27:20,375 classification_efficientnet-b4 INFO: Epoch[29] Iteration[70/78] Loss: 0.003\n\nINFO:classification_efficientnet-b4:Epoch[29] Iteration[70/78] Loss: 0.003\n\n2024-01-01 07:27:24,177 classification_efficientnet-b4 INFO: Training Result: Epoch 29/50, Loss: 0.008, Time epoch: 43.238s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 29/50, Loss: 0.008, Time epoch: 43.238s\n\n2024-01-01 07:27:30,281 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.038, Accuracy: 0.803 F1-Score: 0.647, Precision: 0.711, Recall: 0.615\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.038, Accuracy: 0.803 F1-Score: 0.647, Precision: 0.711, Recall: 0.615\n\n2024-01-01 07:27:30,297 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:27:30,852 classification_efficientnet-b4 INFO: Epoch[30] Iteration[0/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[30] Iteration[0/78] Loss: 0.001\n\n2024-01-01 07:27:36,303 classification_efficientnet-b4 INFO: Epoch[30] Iteration[10/78] Loss: 0.011\n\nINFO:classification_efficientnet-b4:Epoch[30] Iteration[10/78] Loss: 0.011\n\n2024-01-01 07:27:41,917 classification_efficientnet-b4 INFO: Epoch[30] Iteration[20/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[30] Iteration[20/78] Loss: 0.000\n\n2024-01-01 07:27:47,502 classification_efficientnet-b4 INFO: Epoch[30] Iteration[30/78] Loss: 0.002\n\nINFO:classification_efficientnet-b4:Epoch[30] Iteration[30/78] Loss: 0.002\n\n2024-01-01 07:27:52,968 classification_efficientnet-b4 INFO: Epoch[30] Iteration[40/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[30] Iteration[40/78] Loss: 0.000\n\n2024-01-01 07:27:58,612 classification_efficientnet-b4 INFO: Epoch[30] Iteration[50/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[30] Iteration[50/78] Loss: 0.001\n\n2024-01-01 07:28:04,046 classification_efficientnet-b4 INFO: Epoch[30] Iteration[60/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[30] Iteration[60/78] Loss: 0.000\n\n2024-01-01 07:28:09,787 classification_efficientnet-b4 INFO: Epoch[30] Iteration[70/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[30] Iteration[70/78] Loss: 0.001\n\n2024-01-01 07:28:13,489 classification_efficientnet-b4 INFO: Training Result: Epoch 30/50, Loss: 0.005, Time epoch: 43.194s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 30/50, Loss: 0.005, Time epoch: 43.194s\n\n2024-01-01 07:28:18,116 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.037, Accuracy: 0.796 F1-Score: 0.588, Precision: 0.653, Recall: 0.550\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.037, Accuracy: 0.796 F1-Score: 0.588, Precision: 0.653, Recall: 0.550\n\n2024-01-01 07:28:18,128 classification_efficientnet-b4 INFO: Save model at epoch 30, saving model\n\nINFO:classification_efficientnet-b4:Save model at epoch 30, saving model\n\n2024-01-01 07:28:18,721 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:28:19,284 classification_efficientnet-b4 INFO: Epoch[31] Iteration[0/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[31] Iteration[0/78] Loss: 0.001\n\n2024-01-01 07:28:24,984 classification_efficientnet-b4 INFO: Epoch[31] Iteration[10/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[31] Iteration[10/78] Loss: 0.001\n\n2024-01-01 07:28:30,405 classification_efficientnet-b4 INFO: Epoch[31] Iteration[20/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[31] Iteration[20/78] Loss: 0.000\n\n2024-01-01 07:28:36,007 classification_efficientnet-b4 INFO: Epoch[31] Iteration[30/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[31] Iteration[30/78] Loss: 0.001\n\n2024-01-01 07:28:41,379 classification_efficientnet-b4 INFO: Epoch[31] Iteration[40/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[31] Iteration[40/78] Loss: 0.000\n\n2024-01-01 07:28:46,851 classification_efficientnet-b4 INFO: Epoch[31] Iteration[50/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[31] Iteration[50/78] Loss: 0.000\n\n2024-01-01 07:28:52,477 classification_efficientnet-b4 INFO: Epoch[31] Iteration[60/78] Loss: 0.002\n\nINFO:classification_efficientnet-b4:Epoch[31] Iteration[60/78] Loss: 0.002\n\n2024-01-01 07:28:57,822 classification_efficientnet-b4 INFO: Epoch[31] Iteration[70/78] Loss: 0.036\n\nINFO:classification_efficientnet-b4:Epoch[31] Iteration[70/78] Loss: 0.036\n\n2024-01-01 07:29:01,837 classification_efficientnet-b4 INFO: Training Result: Epoch 31/50, Loss: 0.005, Time epoch: 43.120s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 31/50, Loss: 0.005, Time epoch: 43.120s\n\n2024-01-01 07:29:06,478 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.037, Accuracy: 0.771 F1-Score: 0.518, Precision: 0.585, Recall: 0.476\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.037, Accuracy: 0.771 F1-Score: 0.518, Precision: 0.585, Recall: 0.476\n\n2024-01-01 07:29:06,495 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:29:07,046 classification_efficientnet-b4 INFO: Epoch[32] Iteration[0/78] Loss: 0.030\n\nINFO:classification_efficientnet-b4:Epoch[32] Iteration[0/78] Loss: 0.030\n\n2024-01-01 07:29:12,456 classification_efficientnet-b4 INFO: Epoch[32] Iteration[10/78] Loss: 0.003\n\nINFO:classification_efficientnet-b4:Epoch[32] Iteration[10/78] Loss: 0.003\n\n2024-01-01 07:29:18,166 classification_efficientnet-b4 INFO: Epoch[32] Iteration[20/78] Loss: 0.017\n\nINFO:classification_efficientnet-b4:Epoch[32] Iteration[20/78] Loss: 0.017\n\n2024-01-01 07:29:23,548 classification_efficientnet-b4 INFO: Epoch[32] Iteration[30/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[32] Iteration[30/78] Loss: 0.001\n\n2024-01-01 07:29:29,194 classification_efficientnet-b4 INFO: Epoch[32] Iteration[40/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[32] Iteration[40/78] Loss: 0.001\n\n2024-01-01 07:29:34,572 classification_efficientnet-b4 INFO: Epoch[32] Iteration[50/78] Loss: 0.009\n\nINFO:classification_efficientnet-b4:Epoch[32] Iteration[50/78] Loss: 0.009\n\n2024-01-01 07:29:40,156 classification_efficientnet-b4 INFO: Epoch[32] Iteration[60/78] Loss: 0.005\n\nINFO:classification_efficientnet-b4:Epoch[32] Iteration[60/78] Loss: 0.005\n\n2024-01-01 07:29:45,668 classification_efficientnet-b4 INFO: Epoch[32] Iteration[70/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[32] Iteration[70/78] Loss: 0.001\n\n2024-01-01 07:29:49,432 classification_efficientnet-b4 INFO: Training Result: Epoch 32/50, Loss: 0.007, Time epoch: 42.940s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 32/50, Loss: 0.007, Time epoch: 42.940s\n\n2024-01-01 07:29:54,578 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.037, Accuracy: 0.796 F1-Score: 0.569, Precision: 0.627, Recall: 0.536\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.037, Accuracy: 0.796 F1-Score: 0.569, Precision: 0.627, Recall: 0.536\n\n2024-01-01 07:29:54,594 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:29:55,144 classification_efficientnet-b4 INFO: Epoch[33] Iteration[0/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[33] Iteration[0/78] Loss: 0.000\n\n2024-01-01 07:30:00,521 classification_efficientnet-b4 INFO: Epoch[33] Iteration[10/78] Loss: 0.057\n\nINFO:classification_efficientnet-b4:Epoch[33] Iteration[10/78] Loss: 0.057\n\n2024-01-01 07:30:05,999 classification_efficientnet-b4 INFO: Epoch[33] Iteration[20/78] Loss: 0.003\n\nINFO:classification_efficientnet-b4:Epoch[33] Iteration[20/78] Loss: 0.003\n\n2024-01-01 07:30:11,570 classification_efficientnet-b4 INFO: Epoch[33] Iteration[30/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[33] Iteration[30/78] Loss: 0.000\n\n2024-01-01 07:30:16,918 classification_efficientnet-b4 INFO: Epoch[33] Iteration[40/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[33] Iteration[40/78] Loss: 0.001\n\n2024-01-01 07:30:22,593 classification_efficientnet-b4 INFO: Epoch[33] Iteration[50/78] Loss: 0.008\n\nINFO:classification_efficientnet-b4:Epoch[33] Iteration[50/78] Loss: 0.008\n\n2024-01-01 07:30:27,949 classification_efficientnet-b4 INFO: Epoch[33] Iteration[60/78] Loss: 0.005\n\nINFO:classification_efficientnet-b4:Epoch[33] Iteration[60/78] Loss: 0.005\n\n2024-01-01 07:30:33,577 classification_efficientnet-b4 INFO: Epoch[33] Iteration[70/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[33] Iteration[70/78] Loss: 0.001\n\n2024-01-01 07:30:37,284 classification_efficientnet-b4 INFO: Training Result: Epoch 33/50, Loss: 0.006, Time epoch: 42.692s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 33/50, Loss: 0.006, Time epoch: 42.692s\n\n2024-01-01 07:30:41,851 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.037, Accuracy: 0.815 F1-Score: 0.592, Precision: 0.643, Recall: 0.560\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.037, Accuracy: 0.815 F1-Score: 0.592, Precision: 0.643, Recall: 0.560\n\n2024-01-01 07:30:41,867 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:30:42,411 classification_efficientnet-b4 INFO: Epoch[34] Iteration[0/78] Loss: 0.002\n\nINFO:classification_efficientnet-b4:Epoch[34] Iteration[0/78] Loss: 0.002\n\n2024-01-01 07:30:48,084 classification_efficientnet-b4 INFO: Epoch[34] Iteration[10/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[34] Iteration[10/78] Loss: 0.001\n\n2024-01-01 07:30:53,451 classification_efficientnet-b4 INFO: Epoch[34] Iteration[20/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[34] Iteration[20/78] Loss: 0.000\n\n2024-01-01 07:30:58,947 classification_efficientnet-b4 INFO: Epoch[34] Iteration[30/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[34] Iteration[30/78] Loss: 0.000\n\n2024-01-01 07:31:04,315 classification_efficientnet-b4 INFO: Epoch[34] Iteration[40/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[34] Iteration[40/78] Loss: 0.000\n\n2024-01-01 07:31:09,667 classification_efficientnet-b4 INFO: Epoch[34] Iteration[50/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[34] Iteration[50/78] Loss: 0.000\n\n2024-01-01 07:31:15,330 classification_efficientnet-b4 INFO: Epoch[34] Iteration[60/78] Loss: 0.002\n\nINFO:classification_efficientnet-b4:Epoch[34] Iteration[60/78] Loss: 0.002\n\n2024-01-01 07:31:20,705 classification_efficientnet-b4 INFO: Epoch[34] Iteration[70/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[34] Iteration[70/78] Loss: 0.000\n\n2024-01-01 07:31:24,541 classification_efficientnet-b4 INFO: Training Result: Epoch 34/50, Loss: 0.003, Time epoch: 42.677s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 34/50, Loss: 0.003, Time epoch: 42.677s\n\n2024-01-01 07:31:29,295 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.037, Accuracy: 0.758 F1-Score: 0.539, Precision: 0.610, Recall: 0.501\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.037, Accuracy: 0.758 F1-Score: 0.539, Precision: 0.610, Recall: 0.501\n\n2024-01-01 07:31:29,310 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:31:29,850 classification_efficientnet-b4 INFO: Epoch[35] Iteration[0/78] Loss: 0.014\n\nINFO:classification_efficientnet-b4:Epoch[35] Iteration[0/78] Loss: 0.014\n\n2024-01-01 07:31:35,198 classification_efficientnet-b4 INFO: Epoch[35] Iteration[10/78] Loss: 0.025\n\nINFO:classification_efficientnet-b4:Epoch[35] Iteration[10/78] Loss: 0.025\n\n2024-01-01 07:31:40,890 classification_efficientnet-b4 INFO: Epoch[35] Iteration[20/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[35] Iteration[20/78] Loss: 0.000\n\n2024-01-01 07:31:46,272 classification_efficientnet-b4 INFO: Epoch[35] Iteration[30/78] Loss: 0.016\n\nINFO:classification_efficientnet-b4:Epoch[35] Iteration[30/78] Loss: 0.016\n\n2024-01-01 07:31:51,855 classification_efficientnet-b4 INFO: Epoch[35] Iteration[40/78] Loss: 0.005\n\nINFO:classification_efficientnet-b4:Epoch[35] Iteration[40/78] Loss: 0.005\n\n2024-01-01 07:31:57,223 classification_efficientnet-b4 INFO: Epoch[35] Iteration[50/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[35] Iteration[50/78] Loss: 0.000\n\n2024-01-01 07:32:02,605 classification_efficientnet-b4 INFO: Epoch[35] Iteration[60/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[35] Iteration[60/78] Loss: 0.000\n\n2024-01-01 07:32:08,143 classification_efficientnet-b4 INFO: Epoch[35] Iteration[70/78] Loss: 0.189\n\nINFO:classification_efficientnet-b4:Epoch[35] Iteration[70/78] Loss: 0.189\n\n2024-01-01 07:32:11,835 classification_efficientnet-b4 INFO: Training Result: Epoch 35/50, Loss: 0.006, Time epoch: 42.527s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 35/50, Loss: 0.006, Time epoch: 42.527s\n\n2024-01-01 07:32:16,788 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.039, Accuracy: 0.618 F1-Score: 0.424, Precision: 0.533, Recall: 0.380\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.039, Accuracy: 0.618 F1-Score: 0.424, Precision: 0.533, Recall: 0.380\n\n2024-01-01 07:32:16,805 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:32:17,416 classification_efficientnet-b4 INFO: Epoch[36] Iteration[0/78] Loss: 0.002\n\nINFO:classification_efficientnet-b4:Epoch[36] Iteration[0/78] Loss: 0.002\n\n2024-01-01 07:32:22,822 classification_efficientnet-b4 INFO: Epoch[36] Iteration[10/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[36] Iteration[10/78] Loss: 0.001\n\n2024-01-01 07:32:28,161 classification_efficientnet-b4 INFO: Epoch[36] Iteration[20/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[36] Iteration[20/78] Loss: 0.000\n\n2024-01-01 07:32:33,788 classification_efficientnet-b4 INFO: Epoch[36] Iteration[30/78] Loss: 0.003\n\nINFO:classification_efficientnet-b4:Epoch[36] Iteration[30/78] Loss: 0.003\n\n2024-01-01 07:32:39,159 classification_efficientnet-b4 INFO: Epoch[36] Iteration[40/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[36] Iteration[40/78] Loss: 0.000\n\n2024-01-01 07:32:44,811 classification_efficientnet-b4 INFO: Epoch[36] Iteration[50/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[36] Iteration[50/78] Loss: 0.000\n\n2024-01-01 07:32:50,202 classification_efficientnet-b4 INFO: Epoch[36] Iteration[60/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[36] Iteration[60/78] Loss: 0.000\n\n2024-01-01 07:32:55,713 classification_efficientnet-b4 INFO: Epoch[36] Iteration[70/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[36] Iteration[70/78] Loss: 0.000\n\n2024-01-01 07:32:59,489 classification_efficientnet-b4 INFO: Training Result: Epoch 36/50, Loss: 0.004, Time epoch: 42.688s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 36/50, Loss: 0.004, Time epoch: 42.688s\n\n2024-01-01 07:33:04,112 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.040, Accuracy: 0.752 F1-Score: 0.586, Precision: 0.661, Recall: 0.550\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.040, Accuracy: 0.752 F1-Score: 0.586, Precision: 0.661, Recall: 0.550\n\n2024-01-01 07:33:04,129 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:33:04,682 classification_efficientnet-b4 INFO: Epoch[37] Iteration[0/78] Loss: 0.007\n\nINFO:classification_efficientnet-b4:Epoch[37] Iteration[0/78] Loss: 0.007\n\n2024-01-01 07:33:10,412 classification_efficientnet-b4 INFO: Epoch[37] Iteration[10/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[37] Iteration[10/78] Loss: 0.001\n\n2024-01-01 07:33:15,814 classification_efficientnet-b4 INFO: Epoch[37] Iteration[20/78] Loss: 0.024\n\nINFO:classification_efficientnet-b4:Epoch[37] Iteration[20/78] Loss: 0.024\n\n2024-01-01 07:33:21,283 classification_efficientnet-b4 INFO: Epoch[37] Iteration[30/78] Loss: 0.010\n\nINFO:classification_efficientnet-b4:Epoch[37] Iteration[30/78] Loss: 0.010\n\n2024-01-01 07:33:26,837 classification_efficientnet-b4 INFO: Epoch[37] Iteration[40/78] Loss: 0.002\n\nINFO:classification_efficientnet-b4:Epoch[37] Iteration[40/78] Loss: 0.002\n\n2024-01-01 07:33:32,216 classification_efficientnet-b4 INFO: Epoch[37] Iteration[50/78] Loss: 0.003\n\nINFO:classification_efficientnet-b4:Epoch[37] Iteration[50/78] Loss: 0.003\n\n2024-01-01 07:33:37,832 classification_efficientnet-b4 INFO: Epoch[37] Iteration[60/78] Loss: 0.015\n\nINFO:classification_efficientnet-b4:Epoch[37] Iteration[60/78] Loss: 0.015\n\n2024-01-01 07:33:43,235 classification_efficientnet-b4 INFO: Epoch[37] Iteration[70/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[37] Iteration[70/78] Loss: 0.000\n\n2024-01-01 07:33:47,030 classification_efficientnet-b4 INFO: Training Result: Epoch 37/50, Loss: 0.008, Time epoch: 42.903s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 37/50, Loss: 0.008, Time epoch: 42.903s\n\n2024-01-01 07:33:51,910 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.039, Accuracy: 0.783 F1-Score: 0.539, Precision: 0.601, Recall: 0.498\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.039, Accuracy: 0.783 F1-Score: 0.539, Precision: 0.601, Recall: 0.498\n\n2024-01-01 07:33:51,926 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:33:52,475 classification_efficientnet-b4 INFO: Epoch[38] Iteration[0/78] Loss: 0.005\n\nINFO:classification_efficientnet-b4:Epoch[38] Iteration[0/78] Loss: 0.005\n\n2024-01-01 07:33:57,864 classification_efficientnet-b4 INFO: Epoch[38] Iteration[10/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[38] Iteration[10/78] Loss: 0.000\n\n2024-01-01 07:34:03,448 classification_efficientnet-b4 INFO: Epoch[38] Iteration[20/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[38] Iteration[20/78] Loss: 0.000\n\n2024-01-01 07:34:08,810 classification_efficientnet-b4 INFO: Epoch[38] Iteration[30/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[38] Iteration[30/78] Loss: 0.000\n\n2024-01-01 07:34:14,402 classification_efficientnet-b4 INFO: Epoch[38] Iteration[40/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[38] Iteration[40/78] Loss: 0.001\n\n2024-01-01 07:34:19,848 classification_efficientnet-b4 INFO: Epoch[38] Iteration[50/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[38] Iteration[50/78] Loss: 0.000\n\n2024-01-01 07:34:25,210 classification_efficientnet-b4 INFO: Epoch[38] Iteration[60/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[38] Iteration[60/78] Loss: 0.000\n\n2024-01-01 07:34:30,884 classification_efficientnet-b4 INFO: Epoch[38] Iteration[70/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[38] Iteration[70/78] Loss: 0.000\n\n2024-01-01 07:34:34,596 classification_efficientnet-b4 INFO: Training Result: Epoch 38/50, Loss: 0.001, Time epoch: 42.673s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 38/50, Loss: 0.001, Time epoch: 42.673s\n\n2024-01-01 07:34:39,437 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.039, Accuracy: 0.822 F1-Score: 0.615, Precision: 0.660, Recall: 0.584\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.039, Accuracy: 0.822 F1-Score: 0.615, Precision: 0.660, Recall: 0.584\n\n2024-01-01 07:34:39,461 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:34:40,059 classification_efficientnet-b4 INFO: Epoch[39] Iteration[0/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[39] Iteration[0/78] Loss: 0.000\n\n2024-01-01 07:34:45,494 classification_efficientnet-b4 INFO: Epoch[39] Iteration[10/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[39] Iteration[10/78] Loss: 0.000\n\n2024-01-01 07:34:50,881 classification_efficientnet-b4 INFO: Epoch[39] Iteration[20/78] Loss: 0.002\n\nINFO:classification_efficientnet-b4:Epoch[39] Iteration[20/78] Loss: 0.002\n\n2024-01-01 07:34:56,490 classification_efficientnet-b4 INFO: Epoch[39] Iteration[30/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[39] Iteration[30/78] Loss: 0.000\n\n2024-01-01 07:35:01,796 classification_efficientnet-b4 INFO: Epoch[39] Iteration[40/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[39] Iteration[40/78] Loss: 0.000\n\n2024-01-01 07:35:07,414 classification_efficientnet-b4 INFO: Epoch[39] Iteration[50/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[39] Iteration[50/78] Loss: 0.001\n\n2024-01-01 07:35:12,759 classification_efficientnet-b4 INFO: Epoch[39] Iteration[60/78] Loss: 0.002\n\nINFO:classification_efficientnet-b4:Epoch[39] Iteration[60/78] Loss: 0.002\n\n2024-01-01 07:35:18,181 classification_efficientnet-b4 INFO: Epoch[39] Iteration[70/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[39] Iteration[70/78] Loss: 0.000\n\n2024-01-01 07:35:22,006 classification_efficientnet-b4 INFO: Training Result: Epoch 39/50, Loss: 0.001, Time epoch: 42.549s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 39/50, Loss: 0.001, Time epoch: 42.549s\n\n2024-01-01 07:35:26,523 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.039, Accuracy: 0.841 F1-Score: 0.601, Precision: 0.652, Recall: 0.567\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.039, Accuracy: 0.841 F1-Score: 0.601, Precision: 0.652, Recall: 0.567\n\n2024-01-01 07:35:26,537 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:35:27,068 classification_efficientnet-b4 INFO: Epoch[40] Iteration[0/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[40] Iteration[0/78] Loss: 0.000\n\n2024-01-01 07:35:32,673 classification_efficientnet-b4 INFO: Epoch[40] Iteration[10/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[40] Iteration[10/78] Loss: 0.000\n\n2024-01-01 07:35:38,083 classification_efficientnet-b4 INFO: Epoch[40] Iteration[20/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[40] Iteration[20/78] Loss: 0.000\n\n2024-01-01 07:35:43,508 classification_efficientnet-b4 INFO: Epoch[40] Iteration[30/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[40] Iteration[30/78] Loss: 0.000\n\n2024-01-01 07:35:49,099 classification_efficientnet-b4 INFO: Epoch[40] Iteration[40/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[40] Iteration[40/78] Loss: 0.000\n\n2024-01-01 07:35:54,419 classification_efficientnet-b4 INFO: Epoch[40] Iteration[50/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[40] Iteration[50/78] Loss: 0.000\n\n2024-01-01 07:36:00,009 classification_efficientnet-b4 INFO: Epoch[40] Iteration[60/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[40] Iteration[60/78] Loss: 0.000\n\n2024-01-01 07:36:05,379 classification_efficientnet-b4 INFO: Epoch[40] Iteration[70/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[40] Iteration[70/78] Loss: 0.000\n\n2024-01-01 07:36:09,072 classification_efficientnet-b4 INFO: Training Result: Epoch 40/50, Loss: 0.000, Time epoch: 42.537s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 40/50, Loss: 0.000, Time epoch: 42.537s\n\n2024-01-01 07:36:14,270 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.039, Accuracy: 0.803 F1-Score: 0.557, Precision: 0.609, Recall: 0.521\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.039, Accuracy: 0.803 F1-Score: 0.557, Precision: 0.609, Recall: 0.521\n\n2024-01-01 07:36:14,291 classification_efficientnet-b4 INFO: Save model at epoch 40, saving model\n\nINFO:classification_efficientnet-b4:Save model at epoch 40, saving model\n\n2024-01-01 07:36:15,253 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:36:15,880 classification_efficientnet-b4 INFO: Epoch[41] Iteration[0/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[41] Iteration[0/78] Loss: 0.000\n\n2024-01-01 07:36:21,402 classification_efficientnet-b4 INFO: Epoch[41] Iteration[10/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[41] Iteration[10/78] Loss: 0.000\n\n2024-01-01 07:36:26,994 classification_efficientnet-b4 INFO: Epoch[41] Iteration[20/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[41] Iteration[20/78] Loss: 0.000\n\n2024-01-01 07:36:32,275 classification_efficientnet-b4 INFO: Epoch[41] Iteration[30/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[41] Iteration[30/78] Loss: 0.000\n\n2024-01-01 07:36:37,885 classification_efficientnet-b4 INFO: Epoch[41] Iteration[40/78] Loss: 0.004\n\nINFO:classification_efficientnet-b4:Epoch[41] Iteration[40/78] Loss: 0.004\n\n2024-01-01 07:36:43,281 classification_efficientnet-b4 INFO: Epoch[41] Iteration[50/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[41] Iteration[50/78] Loss: 0.000\n\n2024-01-01 07:36:48,715 classification_efficientnet-b4 INFO: Epoch[41] Iteration[60/78] Loss: 0.004\n\nINFO:classification_efficientnet-b4:Epoch[41] Iteration[60/78] Loss: 0.004\n\n2024-01-01 07:36:54,256 classification_efficientnet-b4 INFO: Epoch[41] Iteration[70/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[41] Iteration[70/78] Loss: 0.000\n\n2024-01-01 07:36:57,962 classification_efficientnet-b4 INFO: Training Result: Epoch 41/50, Loss: 0.002, Time epoch: 42.712s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 41/50, Loss: 0.002, Time epoch: 42.712s\n\n2024-01-01 07:37:02,849 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.040, Accuracy: 0.771 F1-Score: 0.468, Precision: 0.533, Recall: 0.429\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.040, Accuracy: 0.771 F1-Score: 0.468, Precision: 0.533, Recall: 0.429\n\n2024-01-01 07:37:02,869 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:37:03,478 classification_efficientnet-b4 INFO: Epoch[42] Iteration[0/78] Loss: 0.008\n\nINFO:classification_efficientnet-b4:Epoch[42] Iteration[0/78] Loss: 0.008\n\n2024-01-01 07:37:08,850 classification_efficientnet-b4 INFO: Epoch[42] Iteration[10/78] Loss: 0.008\n\nINFO:classification_efficientnet-b4:Epoch[42] Iteration[10/78] Loss: 0.008\n\n2024-01-01 07:37:14,192 classification_efficientnet-b4 INFO: Epoch[42] Iteration[20/78] Loss: 0.002\n\nINFO:classification_efficientnet-b4:Epoch[42] Iteration[20/78] Loss: 0.002\n\n2024-01-01 07:37:19,778 classification_efficientnet-b4 INFO: Epoch[42] Iteration[30/78] Loss: 0.059\n\nINFO:classification_efficientnet-b4:Epoch[42] Iteration[30/78] Loss: 0.059\n\n2024-01-01 07:37:25,175 classification_efficientnet-b4 INFO: Epoch[42] Iteration[40/78] Loss: 0.023\n\nINFO:classification_efficientnet-b4:Epoch[42] Iteration[40/78] Loss: 0.023\n\n2024-01-01 07:37:30,835 classification_efficientnet-b4 INFO: Epoch[42] Iteration[50/78] Loss: 0.022\n\nINFO:classification_efficientnet-b4:Epoch[42] Iteration[50/78] Loss: 0.022\n\n2024-01-01 07:37:36,163 classification_efficientnet-b4 INFO: Epoch[42] Iteration[60/78] Loss: 0.008\n\nINFO:classification_efficientnet-b4:Epoch[42] Iteration[60/78] Loss: 0.008\n\n2024-01-01 07:37:41,643 classification_efficientnet-b4 INFO: Epoch[42] Iteration[70/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[42] Iteration[70/78] Loss: 0.001\n\n2024-01-01 07:37:45,459 classification_efficientnet-b4 INFO: Training Result: Epoch 42/50, Loss: 0.017, Time epoch: 42.594s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 42/50, Loss: 0.017, Time epoch: 42.594s\n\n2024-01-01 07:37:49,984 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.040, Accuracy: 0.726 F1-Score: 0.443, Precision: 0.514, Recall: 0.398\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.040, Accuracy: 0.726 F1-Score: 0.443, Precision: 0.514, Recall: 0.398\n\n2024-01-01 07:37:50,000 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:37:50,540 classification_efficientnet-b4 INFO: Epoch[43] Iteration[0/78] Loss: 0.040\n\nINFO:classification_efficientnet-b4:Epoch[43] Iteration[0/78] Loss: 0.040\n\n2024-01-01 07:37:56,116 classification_efficientnet-b4 INFO: Epoch[43] Iteration[10/78] Loss: 0.009\n\nINFO:classification_efficientnet-b4:Epoch[43] Iteration[10/78] Loss: 0.009\n\n2024-01-01 07:38:01,423 classification_efficientnet-b4 INFO: Epoch[43] Iteration[20/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[43] Iteration[20/78] Loss: 0.000\n\n2024-01-01 07:38:06,863 classification_efficientnet-b4 INFO: Epoch[43] Iteration[30/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[43] Iteration[30/78] Loss: 0.000\n\n2024-01-01 07:38:12,428 classification_efficientnet-b4 INFO: Epoch[43] Iteration[40/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[43] Iteration[40/78] Loss: 0.001\n\n2024-01-01 07:38:17,779 classification_efficientnet-b4 INFO: Epoch[43] Iteration[50/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[43] Iteration[50/78] Loss: 0.001\n\n2024-01-01 07:38:23,441 classification_efficientnet-b4 INFO: Epoch[43] Iteration[60/78] Loss: 0.010\n\nINFO:classification_efficientnet-b4:Epoch[43] Iteration[60/78] Loss: 0.010\n\n2024-01-01 07:38:28,801 classification_efficientnet-b4 INFO: Epoch[43] Iteration[70/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[43] Iteration[70/78] Loss: 0.001\n\n2024-01-01 07:38:32,542 classification_efficientnet-b4 INFO: Training Result: Epoch 43/50, Loss: 0.006, Time epoch: 42.545s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 43/50, Loss: 0.006, Time epoch: 42.545s\n\n2024-01-01 07:38:37,574 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.040, Accuracy: 0.758 F1-Score: 0.502, Precision: 0.564, Recall: 0.463\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.040, Accuracy: 0.758 F1-Score: 0.502, Precision: 0.564, Recall: 0.463\n\n2024-01-01 07:38:37,590 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:38:38,124 classification_efficientnet-b4 INFO: Epoch[44] Iteration[0/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[44] Iteration[0/78] Loss: 0.000\n\n2024-01-01 07:38:43,511 classification_efficientnet-b4 INFO: Epoch[44] Iteration[10/78] Loss: 0.005\n\nINFO:classification_efficientnet-b4:Epoch[44] Iteration[10/78] Loss: 0.005\n\n2024-01-01 07:38:49,084 classification_efficientnet-b4 INFO: Epoch[44] Iteration[20/78] Loss: 0.026\n\nINFO:classification_efficientnet-b4:Epoch[44] Iteration[20/78] Loss: 0.026\n\n2024-01-01 07:38:54,434 classification_efficientnet-b4 INFO: Epoch[44] Iteration[30/78] Loss: 0.003\n\nINFO:classification_efficientnet-b4:Epoch[44] Iteration[30/78] Loss: 0.003\n\n2024-01-01 07:38:59,906 classification_efficientnet-b4 INFO: Epoch[44] Iteration[40/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[44] Iteration[40/78] Loss: 0.001\n\n2024-01-01 07:39:05,361 classification_efficientnet-b4 INFO: Epoch[44] Iteration[50/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[44] Iteration[50/78] Loss: 0.001\n\n2024-01-01 07:39:10,730 classification_efficientnet-b4 INFO: Epoch[44] Iteration[60/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[44] Iteration[60/78] Loss: 0.001\n\n2024-01-01 07:39:16,317 classification_efficientnet-b4 INFO: Epoch[44] Iteration[70/78] Loss: 0.013\n\nINFO:classification_efficientnet-b4:Epoch[44] Iteration[70/78] Loss: 0.013\n\n2024-01-01 07:39:19,985 classification_efficientnet-b4 INFO: Training Result: Epoch 44/50, Loss: 0.004, Time epoch: 42.396s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 44/50, Loss: 0.004, Time epoch: 42.396s\n\n2024-01-01 07:39:24,586 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.040, Accuracy: 0.809 F1-Score: 0.570, Precision: 0.626, Recall: 0.533\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.040, Accuracy: 0.809 F1-Score: 0.570, Precision: 0.626, Recall: 0.533\n\n2024-01-01 07:39:24,610 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:39:25,180 classification_efficientnet-b4 INFO: Epoch[45] Iteration[0/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[45] Iteration[0/78] Loss: 0.000\n\n2024-01-01 07:39:30,701 classification_efficientnet-b4 INFO: Epoch[45] Iteration[10/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[45] Iteration[10/78] Loss: 0.000\n\n2024-01-01 07:39:36,041 classification_efficientnet-b4 INFO: Epoch[45] Iteration[20/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[45] Iteration[20/78] Loss: 0.000\n\n2024-01-01 07:39:41,675 classification_efficientnet-b4 INFO: Epoch[45] Iteration[30/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[45] Iteration[30/78] Loss: 0.000\n\n2024-01-01 07:39:47,002 classification_efficientnet-b4 INFO: Epoch[45] Iteration[40/78] Loss: 0.002\n\nINFO:classification_efficientnet-b4:Epoch[45] Iteration[40/78] Loss: 0.002\n\n2024-01-01 07:39:52,556 classification_efficientnet-b4 INFO: Epoch[45] Iteration[50/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[45] Iteration[50/78] Loss: 0.001\n\n2024-01-01 07:39:57,955 classification_efficientnet-b4 INFO: Epoch[45] Iteration[60/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[45] Iteration[60/78] Loss: 0.000\n\n2024-01-01 07:40:03,323 classification_efficientnet-b4 INFO: Epoch[45] Iteration[70/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[45] Iteration[70/78] Loss: 0.000\n\n2024-01-01 07:40:07,173 classification_efficientnet-b4 INFO: Training Result: Epoch 45/50, Loss: 0.003, Time epoch: 42.567s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 45/50, Loss: 0.003, Time epoch: 42.567s\n\n2024-01-01 07:40:11,690 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.040, Accuracy: 0.777 F1-Score: 0.555, Precision: 0.627, Recall: 0.513\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.040, Accuracy: 0.777 F1-Score: 0.555, Precision: 0.627, Recall: 0.513\n\n2024-01-01 07:40:11,704 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:40:12,232 classification_efficientnet-b4 INFO: Epoch[46] Iteration[0/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[46] Iteration[0/78] Loss: 0.000\n\n2024-01-01 07:40:17,626 classification_efficientnet-b4 INFO: Epoch[46] Iteration[10/78] Loss: 0.012\n\nINFO:classification_efficientnet-b4:Epoch[46] Iteration[10/78] Loss: 0.012\n\n2024-01-01 07:40:23,078 classification_efficientnet-b4 INFO: Epoch[46] Iteration[20/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[46] Iteration[20/78] Loss: 0.000\n\n2024-01-01 07:40:28,449 classification_efficientnet-b4 INFO: Epoch[46] Iteration[30/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[46] Iteration[30/78] Loss: 0.001\n\n2024-01-01 07:40:34,115 classification_efficientnet-b4 INFO: Epoch[46] Iteration[40/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[46] Iteration[40/78] Loss: 0.000\n\n2024-01-01 07:40:39,506 classification_efficientnet-b4 INFO: Epoch[46] Iteration[50/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[46] Iteration[50/78] Loss: 0.000\n\n2024-01-01 07:40:45,119 classification_efficientnet-b4 INFO: Epoch[46] Iteration[60/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[46] Iteration[60/78] Loss: 0.000\n\n2024-01-01 07:40:50,443 classification_efficientnet-b4 INFO: Epoch[46] Iteration[70/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[46] Iteration[70/78] Loss: 0.000\n\n2024-01-01 07:40:54,151 classification_efficientnet-b4 INFO: Training Result: Epoch 46/50, Loss: 0.002, Time epoch: 42.449s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 46/50, Loss: 0.002, Time epoch: 42.449s\n\n2024-01-01 07:40:59,306 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.040, Accuracy: 0.771 F1-Score: 0.474, Precision: 0.533, Recall: 0.433\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.040, Accuracy: 0.771 F1-Score: 0.474, Precision: 0.533, Recall: 0.433\n\n2024-01-01 07:40:59,323 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:40:59,866 classification_efficientnet-b4 INFO: Epoch[47] Iteration[0/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[47] Iteration[0/78] Loss: 0.000\n\n2024-01-01 07:41:05,156 classification_efficientnet-b4 INFO: Epoch[47] Iteration[10/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[47] Iteration[10/78] Loss: 0.000\n\n2024-01-01 07:41:10,684 classification_efficientnet-b4 INFO: Epoch[47] Iteration[20/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[47] Iteration[20/78] Loss: 0.001\n\n2024-01-01 07:41:16,057 classification_efficientnet-b4 INFO: Epoch[47] Iteration[30/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[47] Iteration[30/78] Loss: 0.000\n\n2024-01-01 07:41:21,447 classification_efficientnet-b4 INFO: Epoch[47] Iteration[40/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[47] Iteration[40/78] Loss: 0.000\n\n2024-01-01 07:41:27,069 classification_efficientnet-b4 INFO: Epoch[47] Iteration[50/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[47] Iteration[50/78] Loss: 0.000\n\n2024-01-01 07:41:32,387 classification_efficientnet-b4 INFO: Epoch[47] Iteration[60/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[47] Iteration[60/78] Loss: 0.000\n\n2024-01-01 07:41:37,938 classification_efficientnet-b4 INFO: Epoch[47] Iteration[70/78] Loss: 0.003\n\nINFO:classification_efficientnet-b4:Epoch[47] Iteration[70/78] Loss: 0.003\n\n2024-01-01 07:41:41,663 classification_efficientnet-b4 INFO: Training Result: Epoch 47/50, Loss: 0.002, Time epoch: 42.342s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 47/50, Loss: 0.002, Time epoch: 42.342s\n\n2024-01-01 07:41:46,139 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.040, Accuracy: 0.809 F1-Score: 0.502, Precision: 0.558, Recall: 0.463\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.040, Accuracy: 0.809 F1-Score: 0.502, Precision: 0.558, Recall: 0.463\n\n2024-01-01 07:41:46,153 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:41:46,687 classification_efficientnet-b4 INFO: Epoch[48] Iteration[0/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[48] Iteration[0/78] Loss: 0.000\n\n2024-01-01 07:41:52,274 classification_efficientnet-b4 INFO: Epoch[48] Iteration[10/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[48] Iteration[10/78] Loss: 0.000\n\n2024-01-01 07:41:57,586 classification_efficientnet-b4 INFO: Epoch[48] Iteration[20/78] Loss: 0.003\n\nINFO:classification_efficientnet-b4:Epoch[48] Iteration[20/78] Loss: 0.003\n\n2024-01-01 07:42:03,185 classification_efficientnet-b4 INFO: Epoch[48] Iteration[30/78] Loss: 0.002\n\nINFO:classification_efficientnet-b4:Epoch[48] Iteration[30/78] Loss: 0.002\n\n2024-01-01 07:42:08,515 classification_efficientnet-b4 INFO: Epoch[48] Iteration[40/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[48] Iteration[40/78] Loss: 0.000\n\n2024-01-01 07:42:13,940 classification_efficientnet-b4 INFO: Epoch[48] Iteration[50/78] Loss: 0.002\n\nINFO:classification_efficientnet-b4:Epoch[48] Iteration[50/78] Loss: 0.002\n\n2024-01-01 07:42:19,457 classification_efficientnet-b4 INFO: Epoch[48] Iteration[60/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[48] Iteration[60/78] Loss: 0.000\n\n2024-01-01 07:42:24,806 classification_efficientnet-b4 INFO: Epoch[48] Iteration[70/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[48] Iteration[70/78] Loss: 0.000\n\n2024-01-01 07:42:28,735 classification_efficientnet-b4 INFO: Training Result: Epoch 48/50, Loss: 0.002, Time epoch: 42.584s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 48/50, Loss: 0.002, Time epoch: 42.584s\n\n2024-01-01 07:42:33,263 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.041, Accuracy: 0.771 F1-Score: 0.542, Precision: 0.601, Recall: 0.506\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.041, Accuracy: 0.771 F1-Score: 0.542, Precision: 0.601, Recall: 0.506\n\n2024-01-01 07:42:33,278 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:42:33,805 classification_efficientnet-b4 INFO: Epoch[49] Iteration[0/78] Loss: 0.001\n\nINFO:classification_efficientnet-b4:Epoch[49] Iteration[0/78] Loss: 0.001\n\n2024-01-01 07:42:39,239 classification_efficientnet-b4 INFO: Epoch[49] Iteration[10/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[49] Iteration[10/78] Loss: 0.000\n\n2024-01-01 07:42:44,820 classification_efficientnet-b4 INFO: Epoch[49] Iteration[20/78] Loss: 0.009\n\nINFO:classification_efficientnet-b4:Epoch[49] Iteration[20/78] Loss: 0.009\n\n2024-01-01 07:42:50,146 classification_efficientnet-b4 INFO: Epoch[49] Iteration[30/78] Loss: 0.006\n\nINFO:classification_efficientnet-b4:Epoch[49] Iteration[30/78] Loss: 0.006\n\n2024-01-01 07:42:55,777 classification_efficientnet-b4 INFO: Epoch[49] Iteration[40/78] Loss: 0.003\n\nINFO:classification_efficientnet-b4:Epoch[49] Iteration[40/78] Loss: 0.003\n\n2024-01-01 07:43:01,123 classification_efficientnet-b4 INFO: Epoch[49] Iteration[50/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[49] Iteration[50/78] Loss: 0.000\n\n2024-01-01 07:43:06,624 classification_efficientnet-b4 INFO: Epoch[49] Iteration[60/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[49] Iteration[60/78] Loss: 0.000\n\n2024-01-01 07:43:12,146 classification_efficientnet-b4 INFO: Epoch[49] Iteration[70/78] Loss: 0.003\n\nINFO:classification_efficientnet-b4:Epoch[49] Iteration[70/78] Loss: 0.003\n\n2024-01-01 07:43:15,773 classification_efficientnet-b4 INFO: Training Result: Epoch 49/50, Loss: 0.004, Time epoch: 42.498s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 49/50, Loss: 0.004, Time epoch: 42.498s\n\n2024-01-01 07:43:20,858 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.041, Accuracy: 0.803 F1-Score: 0.606, Precision: 0.669, Recall: 0.568\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.041, Accuracy: 0.803 F1-Score: 0.606, Precision: 0.669, Recall: 0.568\n\n2024-01-01 07:43:20,875 classification_efficientnet-b4 INFO: Start training\n\nINFO:classification_efficientnet-b4:Start training\n\n2024-01-01 07:43:21,416 classification_efficientnet-b4 INFO: Epoch[50] Iteration[0/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[50] Iteration[0/78] Loss: 0.000\n\n2024-01-01 07:43:26,727 classification_efficientnet-b4 INFO: Epoch[50] Iteration[10/78] Loss: 0.002\n\nINFO:classification_efficientnet-b4:Epoch[50] Iteration[10/78] Loss: 0.002\n\n2024-01-01 07:43:32,155 classification_efficientnet-b4 INFO: Epoch[50] Iteration[20/78] Loss: 0.011\n\nINFO:classification_efficientnet-b4:Epoch[50] Iteration[20/78] Loss: 0.011\n\n2024-01-01 07:43:37,634 classification_efficientnet-b4 INFO: Epoch[50] Iteration[30/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[50] Iteration[30/78] Loss: 0.000\n\n2024-01-01 07:43:42,970 classification_efficientnet-b4 INFO: Epoch[50] Iteration[40/78] Loss: 0.006\n\nINFO:classification_efficientnet-b4:Epoch[50] Iteration[40/78] Loss: 0.006\n\n2024-01-01 07:43:48,658 classification_efficientnet-b4 INFO: Epoch[50] Iteration[50/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[50] Iteration[50/78] Loss: 0.000\n\n2024-01-01 07:43:54,035 classification_efficientnet-b4 INFO: Epoch[50] Iteration[60/78] Loss: 0.002\n\nINFO:classification_efficientnet-b4:Epoch[50] Iteration[60/78] Loss: 0.002\n\n2024-01-01 07:43:59,656 classification_efficientnet-b4 INFO: Epoch[50] Iteration[70/78] Loss: 0.000\n\nINFO:classification_efficientnet-b4:Epoch[50] Iteration[70/78] Loss: 0.000\n\n2024-01-01 07:44:03,348 classification_efficientnet-b4 INFO: Training Result: Epoch 50/50, Loss: 0.002, Time epoch: 42.476s\n\nINFO:classification_efficientnet-b4:Training Result: Epoch 50/50, Loss: 0.002, Time epoch: 42.476s\n\n2024-01-01 07:44:07,856 classification_efficientnet-b4 INFO: Validation Result: Loss: 0.041, Accuracy: 0.796 F1-Score: 0.498, Precision: 0.558, Recall: 0.458\n\nINFO:classification_efficientnet-b4:Validation Result: Loss: 0.041, Accuracy: 0.796 F1-Score: 0.498, Precision: 0.558, Recall: 0.458\n\n2024-01-01 07:44:07,869 classification_efficientnet-b4 INFO: Save model at epoch 50, saving model\n\nINFO:classification_efficientnet-b4:Save model at epoch 50, saving model\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3. Setup Segmentation"
      ],
      "metadata": {
        "id": "-zwShcDQwtGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(folds):\n",
        "    for fold in range(N_FOLDS):\n",
        "        #TASK\n",
        "        TASK = \"segmentation\"\n",
        "\n",
        "        #Path\n",
        "        weight_dir, log_dir, logger_name = init_path(TASK)\n",
        "\n",
        "\n",
        "        #Model\n",
        "        model = segmentation_model().to(DEVICE)\n",
        "\n",
        "        #Loss & Optimizer\n",
        "        model = model.to(DEVICE)\n",
        "        dice_loss = smp.losses.DiceLoss(mode='binary', from_logits=True)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=BASE_LR, weight_decay=1e-5)\n",
        "\n",
        "\n",
        "        #Meters\n",
        "        overall_meter = ###\n",
        "        iou_meter = ###\n",
        "        dice_meter = ###\n",
        "        train_loss_meter = ###\n",
        "        val_loss_meter = ###\n",
        "        precision_meter = ###\n",
        "        recall_meter = ###\n",
        "        f1_score_meter = ###\n",
        "\n",
        "        train_images, val_images = folds[fold]\n",
        "        train_set = #### CODE HERE\n",
        "        val_set = #### CODE HERE\n",
        "\n",
        "        train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
        "        val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
        "\n",
        "        logger = setup_logger(logger_name, log_dir)\n",
        "        stale = 0\n",
        "        best_overall = 0\n",
        "        start_epoch = 1\n",
        "\n",
        "        if CHECKPOINT is not None:\n",
        "            if os.path.exists(CHECKPOINT):\n",
        "                checkpoint = torch.load(CHECKPOINT)\n",
        "                model.load_state_dict(checkpoint['model_state_dict'])\n",
        "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "                start_epoch = checkpoint['epoch']\n",
        "                best_overall = checkpoint['best_overall']\n",
        "                logger.info(f\"Resume training from epoch {start_epoch}\")\n",
        "            else:\n",
        "                logger.info(f\"Checkpoint not found, start training from epoch 1\")\n",
        "        #Logging hyperparameters\n",
        "        logging_hyperparameters(logger)\n",
        "\n",
        "        for epoch in range(start_epoch, 1+MAX_EPOCHS):\n",
        "            start_time = time.time()\n",
        "            #Train\n",
        "            model.train()\n",
        "            #Reset meters\n",
        "            overall_meter.reset()\n",
        "            train_loss_meter.reset()\n",
        "            val_loss_meter.reset()\n",
        "\n",
        "            iou_meter.reset()\n",
        "            dice_meter.reset()\n",
        "            precision_meter.reset()\n",
        "            recall_meter.reset()\n",
        "            f1_score_meter.reset()\n",
        "\n",
        "            logger.info(\"Start training\")\n",
        "            for batch_idx, (image, mask, _) in enumerate(train_loader):\n",
        "                n = image.shape[0]\n",
        "                optimizer.zero_grad()\n",
        "                image = image.to(DEVICE)\n",
        "                mask = mask.to(DEVICE)\n",
        "\n",
        "                output = ####\n",
        "                #Cal loss\n",
        "                train_loss = ####\n",
        "                train_loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                train_loss_meter.update(train_loss.item(),n)\n",
        "\n",
        "                if batch_idx % 10 == 0:\n",
        "                    logger.info(f\"Epoch[{epoch}] - Fold[{fold}] - Iteration[{batch_idx}/{len(train_loader)}] Loss: {train_loss:.3f}\")\n",
        "            end_time = time.time()\n",
        "            logger.info(f\"Training Result: Epoch {epoch}/{MAX_EPOCHS} - Fold {fold}/{N_FOLDS}, Loss: {train_loss_meter.avg:.3f}, Time epoch: {end_time-start_time:.3f}s\")\n",
        "\n",
        "            #Valid\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                for batch_idx, (image, mask, _) in enumerate(val_loader):\n",
        "                    n = image.shape[0]\n",
        "                    image = image.to(DEVICE)\n",
        "                    mask = mask.to(DEVICE)\n",
        "\n",
        "                    output = model(image)\n",
        "                    val_loss = dice_loss(output, mask)\n",
        "\n",
        "                    # #Calculate metrics\n",
        "                    mask = F.sigmoid(mask).round().long()\n",
        "                    tp, fp, fn, tn = smp.metrics.get_stats(output, mask, mode='binary', threshold=0.5)\n",
        "\n",
        "\n",
        "                    iou_score = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"macro\")\n",
        "\n",
        "                    dice_score = torch.mean((2*tp.sum(0)/(2*tp.sum(0) + fp.sum(0) + fn.sum(0) + 1e-5)))\n",
        "                    precision_score = smp.metrics.precision(tp, fp, fn, tn, reduction=\"macro\")\n",
        "                    recall_score = smp.metrics.recall(tp, fp, fn, tn, reduction=\"macro\")\n",
        "                    f1_score = smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"macro\")\n",
        "\n",
        "\n",
        "                    #Update meters\n",
        "                    val_loss_meter.update(val_loss.item(), n)\n",
        "\n",
        "                    iou_meter.update(iou_score.item(), n)\n",
        "                    dice_meter.update(dice_score.item(), n)\n",
        "                    precision_meter.update(precision_score.item(), n)\n",
        "                    recall_meter.update(recall_score.item(), n)\n",
        "                    f1_score_meter.update(f1_score.item(), n)\n",
        "\n",
        "                    #Overall score\n",
        "                    overall_score = (iou_score + dice_score + f1_score)/3\n",
        "                    overall_meter.update(overall_score.item(), n)\n",
        "\n",
        "            logger.info(f\"Validation Result: Dice Loss: {val_loss_meter.avg:.3f}, IoU: {iou_meter.avg:.3f}, Dice Score: {dice_meter.avg:.3f}, F1-Score: {f1_score_meter.avg:.3f}, Average Score: {overall_meter.avg:.3f}\")\n",
        "\n",
        "            #Save best model\n",
        "            to_save = {\n",
        "                    'epoch': epoch,\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'best_overall': best_overall,\n",
        "                }\n",
        "            if overall_meter.avg > best_overall: # best base on IoU score\n",
        "                logger.info(f\"Best model found at epoch {epoch}, saving model\")\n",
        "\n",
        "                torch.save(to_save, os.path.join(weight_dir,f\"best_epoch{epoch}_fold{fold}_{INPUT_SIZE[0]}_BS={BATCH_SIZE}_average={overall_meter.avg:.3f}.pth\"))\n",
        "                best_overall = overall_meter.avg\n",
        "                stale = 0\n",
        "            else:\n",
        "                stale += 1\n",
        "                if stale > 300:\n",
        "                    logger.info(f\"No improvement {300} consecutive epochs, early stopping\")\n",
        "                    break\n",
        "            if epoch % SAVE_INTERVAL == 0 or epoch == MAX_EPOCHS:\n",
        "                logger.info(f\"Save model at epoch {epoch}, saving model\")\n",
        "                torch.save(to_save, os.path.join(weight_dir,f\"epoch{epoch}_fold{fold}.pth\"))"
      ],
      "metadata": {
        "id": "LO_Jr1C6w4r-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### CODE HERE"
      ],
      "metadata": {
        "id": "QsaIA_bRBiPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Multitask Model"
      ],
      "metadata": {
        "id": "QAD1fxEdxB6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RESNET50_ENCODER_WEIGHTS_URL = \"https://download.pytorch.org/models/resnet50-19c8e357.pth\"\n",
        "\n",
        "def multitask_model():\n",
        "    aux_param=dict(\n",
        "                    pooling='avg',             # one of 'avg', 'max'\n",
        "                    dropout=0.5,               # dropout ratio, default is None\n",
        "                    # activation='sigmoid',      # activation function, default is None\n",
        "                    classes=CLA_NUM_CLASSES,      # define number of output labels\n",
        "                )\n",
        "    model = segmentation_model(aux_param=aux_param)\n",
        "    return model"
      ],
      "metadata": {
        "id": "ZRut7ATHEaT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w7UJPAu8H1r5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(folds):\n",
        "    for fold in range(N_FOLDS):\n",
        "        #Task\n",
        "        TASK = \"multitask\"\n",
        "\n",
        "        #Path\n",
        "        weight_dir, log_dir, logger_name = init_path(TASK)\n",
        "\n",
        "\n",
        "        #Model\n",
        "        model = multitask_model().to(DEVICE)\n",
        "\n",
        "        #Loss & Optimizer\n",
        "        dice_loss = smp.losses.DiceLoss(mode='binary', from_logits=True)\n",
        "        # CE_loss = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "        optimizer = optim.Adam(model.parameters(), lr=BASE_LR, weight_decay=1e-5)\n",
        "\n",
        "\n",
        "\n",
        "        #Common meter\n",
        "        overall_meter = AverageMeter()\n",
        "        train_loss_meter = AverageMeter()\n",
        "        val_loss_meter = AverageMeter()\n",
        "\n",
        "        #Meters segmentation\n",
        "        seg_train_loss_meter = AverageMeter()\n",
        "        seg_val_loss_meter = AverageMeter()\n",
        "        seg_iou_meter = AverageMeter()\n",
        "        seg_dice_meter = AverageMeter()\n",
        "        seg_precision_meter = AverageMeter()\n",
        "        seg_recall_meter = AverageMeter()\n",
        "        seg_f1_score_meter = AverageMeter()\n",
        "\n",
        "        #Meters classification\n",
        "        cla_train_loss_meter = AverageMeter()\n",
        "        cla_val_loss_meter = AverageMeter()\n",
        "        cla_acc_meter = AverageMeter()\n",
        "        cla_precision_meter = AverageMeter()\n",
        "        cla_recall_meter = AverageMeter()\n",
        "        cla_f1_score_meter = AverageMeter()\n",
        "\n",
        "        train_images, val_images = folds[fold]\n",
        "        train_set = ###\n",
        "        val_set = ###\n",
        "\n",
        "        train_loader = ###\n",
        "        val_loader = ###\n",
        "\n",
        "                #Setup logging\n",
        "        logger = setup_logger(logger_name, log_dir)\n",
        "\n",
        "        start_epoch=1\n",
        "        best_overall = 0\n",
        "        stale = 0\n",
        "\n",
        "        if CHECKPOINT is not None:\n",
        "            if os.path.exists(CHECKPOINT):\n",
        "                checkpoint = torch.load(CHECKPOINT)\n",
        "                model.load_state_dict(checkpoint['model_state_dict'])\n",
        "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "                start_epoch = checkpoint['epoch']\n",
        "                best_overall = checkpoint['best_overall']\n",
        "                print(f\"Resume training from epoch {start_epoch}\")\n",
        "            else:\n",
        "                print(f\"Checkpoint not found, start training from epoch 1\")\n",
        "\n",
        "        #Logging hyperparameters\n",
        "        logging_hyperparameters(logger)\n",
        "\n",
        "        for epoch in range(start_epoch, 1+MAX_EPOCHS):\n",
        "            start_time = time.time()\n",
        "            #Train\n",
        "            model.train()\n",
        "\n",
        "            #Reset meters\n",
        "            #Common meter\n",
        "            train_loss_meter.reset()\n",
        "            val_loss_meter.reset()\n",
        "            overall_meter.reset()\n",
        "\n",
        "            #Meters segmentation\n",
        "            seg_iou_meter.reset()\n",
        "            seg_dice_meter.reset()\n",
        "            seg_precision_meter.reset()\n",
        "            seg_recall_meter.reset()\n",
        "            seg_f1_score_meter.reset()\n",
        "\n",
        "            #Meters classification\n",
        "            cla_acc_meter.reset()\n",
        "            cla_precision_meter.reset()\n",
        "            cla_recall_meter.reset()\n",
        "            cla_f1_score_meter.reset()\n",
        "\n",
        "            logger.info(\"Start training\")\n",
        "            for batch_idx, (image, mask, label) in enumerate(train_loader):\n",
        "                n = image.shape[0]\n",
        "                optimizer.zero_grad()\n",
        "                image = image.to(DEVICE)\n",
        "                mask = mask.to(DEVICE)\n",
        "                label = label.to(DEVICE)\n",
        "\n",
        "                #Forward\n",
        "                output_mask, output_classification = model(image)\n",
        "\n",
        "                #Cal loss\n",
        "                loss_segmentation = dice_loss(output_mask, mask)\n",
        "                loss_classification = focal_loss(output_classification, label, alpha=0.25, gamma=2,reduction='mean')\n",
        "                train_loss = ALPHA*loss_segmentation + (1 - ALPHA)*loss_classification\n",
        "\n",
        "                train_loss.backward()\n",
        "                optimizer.step()\n",
        "                train_loss_meter.update(train_loss.item(), n)\n",
        "                seg_train_loss_meter.update(loss_segmentation.item(), n)\n",
        "                cla_train_loss_meter.update(loss_classification.item(), n)\n",
        "                if batch_idx % 10 == 0:\n",
        "                    logger.info(f\"Epoch[{epoch}] Iteration[{batch_idx}/{len(train_loader)}] Loss: {train_loss:.3f}\")\n",
        "\n",
        "            end_time = time.time()\n",
        "            logger.info(f\"Training Result: Epoch {epoch}/{MAX_EPOCHS}, Loss: {train_loss_meter.avg:.3f}  Segmentation loss: {seg_train_loss_meter.avg:.3f} Classification loss: {cla_train_loss_meter.avg:.3f} Time epoch: {end_time-start_time:.3f}s\")\n",
        "\n",
        "            #Valid\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                for batch_idx, (image, mask, label) in enumerate(val_loader):\n",
        "                    n = image.shape[0]\n",
        "                    image = image.to(DEVICE)\n",
        "                    mask = mask.to(DEVICE)\n",
        "                    label = label.to(DEVICE)\n",
        "\n",
        "                    #Forward\n",
        "                    output_mask, output_classification = model(image)\n",
        "\n",
        "                    #Cal loss\n",
        "                    loss_segmentation = dice_loss(output_mask, mask)\n",
        "                    loss_classification = focal_loss(output_classification, label, alpha=0.25, gamma=2,reduction='mean')\n",
        "                    val_loss = ALPHA*loss_segmentation + (1 - ALPHA)*loss_classification\n",
        "\n",
        "\n",
        "                    #Calculate metrics\n",
        "                    #Segmentation: iou, dice, p, r, f1\n",
        "\n",
        "                    mask = F.sigmoid(mask).round().long()\n",
        "                    tp, fp, fn, tn = smp.metrics.get_stats(output_mask, mask, mode='binary', threshold=0.5)\n",
        "\n",
        "\n",
        "                    seg_iou_score = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"macro\")\n",
        "\n",
        "                    seg_dice_score = torch.mean((2*tp.sum(0)/(2*tp.sum(0) + fp.sum(0) + fn.sum(0) + 1e-5)))\n",
        "                    seg_precision_score = smp.metrics.precision(tp, fp, fn, tn, reduction=\"macro\")\n",
        "                    seg_recall_score = smp.metrics.recall(tp, fp, fn, tn, reduction=\"macro\")\n",
        "                    seg_f1_score = smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"macro\")\n",
        "\n",
        "\n",
        "                    #Classification: acc, p, r, f1\n",
        "                    label = label.detach().cpu().numpy()\n",
        "                    output_classification = output_classification.argmax(1).detach().cpu().numpy()\n",
        "\n",
        "                    cla_acc = accuracy_score(label, output_classification)\n",
        "                    cla_precision_score = precision_score(label, output_classification, average='macro', zero_division=0)\n",
        "                    cla_recall_score = recall_score(label, output_classification, average='macro', zero_division=0)\n",
        "                    cla_f1_score = f1_score(label, output_classification, average='macro')\n",
        "\n",
        "\n",
        "                    #Update meters\n",
        "                    val_loss_meter.update(val_loss.item(), n)\n",
        "\n",
        "                    #Segmentation\n",
        "                    seg_val_loss_meter.update(loss_segmentation.item(), n)\n",
        "                    seg_iou_meter.update(seg_iou_score.item(), n)\n",
        "                    seg_dice_meter.update(seg_dice_score.item(), n)\n",
        "                    seg_precision_meter.update(seg_precision_score.item(), n)\n",
        "                    seg_recall_meter.update(seg_recall_score.item(), n)\n",
        "                    seg_f1_score_meter.update(seg_f1_score.item(), n)\n",
        "\n",
        "                    #Classification\n",
        "                    cla_val_loss_meter.update(loss_classification.item(), n)\n",
        "                    cla_acc_meter.update(cla_acc.item(),n)\n",
        "                    cla_precision_meter.update(cla_precision_score.item(), n)\n",
        "                    cla_recall_meter.update(cla_recall_score.item(), n)\n",
        "                    cla_f1_score_meter.update(cla_f1_score.item(), n)\n",
        "\n",
        "                    #Common\n",
        "                    overall_score = ((seg_iou_score + seg_dice_score + seg_f1_score)/3 + cla_f1_score)/2\n",
        "                    overall_meter.update(overall_score.item(), n)\n",
        "\n",
        "            logger.info(f\"Validation Result: Loss: {val_loss_meter.avg:.3f}, Segmentation loss: {seg_val_loss_meter.avg:.3f} Classification loss: {cla_val_loss_meter.avg:.3f} Overal Score: {overall_meter.avg:.3f}\")\n",
        "            logger.info(f\"Classification: Accuracy: {cla_acc_meter.avg:.3f}, F1-Score: {cla_f1_score_meter.avg:.3f}, Precision: {cla_precision_meter.avg:.3f}, Recall: {cla_recall_meter.avg:.3f}\")\n",
        "            logger.info(f\"Segmentation: IoU: {seg_iou_meter.avg:.3f} Dice: {seg_dice_meter.avg:.3f}, F1-score: {seg_f1_score_meter.avg:.3f}, Precision: {seg_precision_meter.avg:.3f}, Recall: {seg_recall_meter.avg:.3f}\")\n",
        "            #Save best model\n",
        "            to_save = {\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'best_overall': best_overall\n",
        "            }\n",
        "            if overall_meter.avg > best_overall: # best base on IoU score\n",
        "                logger.info(f\"Best model found at epoch {epoch}, saving model\")\n",
        "                torch.save(to_save, os.path.join(weight_dir,f\"best_{epoch}_{INPUT_SIZE[0]}_BS={BATCH_SIZE}_overal={overall_meter.avg:.3f}.pth\"))\n",
        "                best_overall = overall_meter.avg\n",
        "                stale = 0\n",
        "            else:\n",
        "                stale += 1\n",
        "                if stale > 300:\n",
        "                    logger.info(f\"No improvement {300} consecutive epochs, early stopping\")\n",
        "                    break\n",
        "            if epoch % SAVE_INTERVAL == 0 or epoch == MAX_EPOCHS:\n",
        "                logger.info(f\"Save model at epoch {epoch}, saving model\")\n",
        "\n",
        "                torch.save(to_save, os.path.join(weight_dir,f\"epoch_{epoch}.pth\"))"
      ],
      "metadata": {
        "id": "n2WKAUEoErUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(folds)"
      ],
      "metadata": {
        "id": "Hh-kohE0Ni9J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}